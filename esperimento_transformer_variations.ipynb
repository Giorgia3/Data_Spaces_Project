{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Giorgia3/Data_Spaces_Project/blob/main/esperimento_transformer_variations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuPjc4y1VLP0"
      },
      "source": [
        "# Transformer su dati covid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhhXm5zd_avO"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjPWoJ1PLhaP"
      },
      "outputs": [],
      "source": [
        "do_training = False\n",
        "do_test = True\n",
        "do_finetuning = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07T2J6IkmupT"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-W3s-dhqf2r"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install -q tf-models-official==2.4.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UySHGE2zVAxe"
      },
      "outputs": [],
      "source": [
        "from transformers import BertModel, BertTokenizer, BertForSequenceClassification, AdamW, get_linear_schedule_with_warmup,AutoTokenizer\n",
        "from transformers import InputExample, InputFeatures, TrainingArguments, Trainer\n",
        "import os.path\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.decomposition import PCA, IncrementalPCA\n",
        "from sklearn.manifold import TSNE\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import csv\n",
        "import numpy as np\n",
        "import numpy.ma as ma\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from enum import Enum\n",
        "import tensorflow as tf\n",
        "import itertools\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from torch import nn\n",
        "import torch.nn.functional\n",
        "import json\n",
        "import tensorflow_hub as hub\n",
        "import keras.backend as KB\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from official import nlp\n",
        "import official.nlp.optimization\n",
        "import time\n",
        "import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.colors import LinearSegmentedColormap, TABLEAU_COLORS\n",
        "from matplotlib.ticker import FuncFormatter, PercentFormatter\n",
        "%matplotlib inline\n",
        "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
        "from mpl_toolkits.axes_grid1.colorbar import colorbar\n",
        "import matplotlib.cm as cm\n",
        "from cycler import cycler\n",
        "import seaborn as sns\n",
        "import itertools\n",
        "from linecache import getline\n",
        "from pathlib import Path\n",
        "import math\n",
        "import gc\n",
        "import json\n",
        "import subprocess\n",
        "import shlex\n",
        "import pickle\n",
        "from statsmodels.stats.proportion import proportion_confint, proportions_ztest\n",
        "import collections\n",
        "from scipy.stats import chisquare\n",
        "import scipy.stats as stats\n",
        "import plotly.express as px\n",
        "import linecache\n",
        "from os import write\n",
        "from tabulate import tabulate\n",
        "import networkx as nx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-g_-8rTf9XCD"
      },
      "outputs": [],
      "source": [
        "!python --version\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7e2p3qp_nHV"
      },
      "source": [
        "#### Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yxO55QurbZY"
      },
      "outputs": [],
      "source": [
        "config_dict = {}\n",
        "config_dict['USE_GPU'] = True\n",
        "# USE_TPU = False\n",
        "config_dict['TASK_TYPE'] = 'attention_analysis' # options:{'singularvalues_ratio_analysis', 'attention_flow', 'simple_test', 'distance_cones_analysis', 'attention_analysis', 'clustering', 'one_vs_all_classification', 'eigenvalues_analysis', 'singularvalues_ratio_analysis', 'von_neumann_entropy_attentions', 'distance_cones_analysis', 'shannon_entropy_attentions'}\n",
        "config_dict['SPIKE_REGION_ANALYSIS'] = True\n",
        "\n",
        "config_dict['REDUCE_N_INPUT_SAMPLES'] = True\n",
        "config_dict['MAX_N_SAMPLES_PER_CLASS'] = 40000\n",
        "\n",
        "config_dict['K'] = 12\n",
        "config_dict['STRIDE'] = 9\n",
        "config_dict['ADD_KMER_TOKENS_TO_VOCAB'] = True\n",
        "config_dict['MIN_N_OCCUR_KMER'] = None\n",
        "\n",
        "config_dict['ALIGNMENT'] = True\n",
        "config_dict['SPLIT_DATA_IN_CHUNKS'] = False\n",
        "if config_dict['SPLIT_DATA_IN_CHUNKS'] or config_dict['ALIGNMENT']:\n",
        "    config_dict['CHUNK_LEN'] = 150\n",
        "    config_dict['CHUNK_STRIDE'] = 150\n",
        "\n",
        "config_dict['TRAIN_BATCH_SIZE'] = 4    # recommended: 32\n",
        "config_dict['EVAL_BATCH_SIZE'] = 4    # recommended: 32\n",
        "config_dict['EPOCHS'] = 2              # recommended: 2-4\n",
        "config_dict['LR'] = 2e-5            #2e-5, #1e-3 # 2e-4\n",
        "\n",
        "# maximum n. of tokens to be considered for each sequence: (CHUNK_LEN-K)/STRIDE +1 (max value supported by Bert-Base: 512)\n",
        "if config_dict['SPLIT_DATA_IN_CHUNKS']:\n",
        "    config_dict['MAX_LENGTH'] = math.ceil((config_dict['CHUNK_LEN']-config_dict['K'])/config_dict['STRIDE'] +1)  \n",
        "else:\n",
        "    config_dict['MAX_LENGTH'] = 512\n",
        "\n",
        "config_dict['EMB_DIM'] = 768  \n",
        "\n",
        "# attention threshold\n",
        "config_dict['THETA'] = 0.3    \n",
        "\n",
        "# MLP for OvsAC\n",
        "config_dict['POSITIVE_CLASS_MLP'] = 'mu'   \n",
        "config_dict['RELEVANT_TOKENS_MLP'] = ['211-214']   \n",
        "config_dict['INPUT_DIM_MLP'] = len(config_dict['RELEVANT_TOKENS_MLP'])*768  \n",
        "config_dict['OUTPUT_DIM_MLP'] = 2    \n",
        "config_dict['TRAIN_BATCH_SIZE_MLP'] = 64   \n",
        "config_dict['EVAL_BATCH_SIZE_MLP'] = 64    \n",
        "config_dict['EPOCHS_MLP'] = 5              \n",
        "config_dict['HIDDEN_UNITS_1_MLP'] = 32              # recommended: 2-4\n",
        "config_dict['HIDDEN_UNITS_2_MLP'] = 32              # recommended: 2-4\n",
        "config_dict['LR_MLP'] = 2e-5            #2e-5, #1e-3 # 2e-4\n",
        "\n",
        "# WEA\n",
        "all_layers_heads = []\n",
        "for head in range(0,12):\n",
        "    for layer in range(0,12):\n",
        "        all_layers_heads.append([layer,head])\n",
        "if config_dict['TASK_TYPE'] == 'distance_cones_analysis' :\n",
        "    all_layers_heads1 = []\n",
        "    for head in range(0,12):\n",
        "        for layer in range(0,12):\n",
        "            all_layers_heads1.append([layer,head])\n",
        "    dc_layer_heads = all_layers_heads1\n",
        "    # dc_layer_heads = []\n",
        "    # for head in range(0,12):\n",
        "    #     dc_layer_heads.append([1-1, head])\n",
        "    config_dict['SELECTED_LAYER_HEAD_LIST'] = dc_layer_heads # distance cones:[[1-1,5-1]]\n",
        "else:\n",
        "    config_dict['SELECTED_LAYER_HEAD_LIST'] = all_layers_heads #[[1-1,4-1], [12-1,9-1], [11-1, 5-1], [1-1, 5-1], [5-1, 10-1]] #all_layers_heads \n",
        "config_dict['SELECTED_CLASS'] = \"omicron\"\n",
        "config_dict['BASES'] = ['A','C','G','T','N', 'W', 'S', 'M', 'K', 'R', 'Y']\n",
        "\n",
        "def generate_config_str():\n",
        "    str_conf = '--------------------------------------------------------------\\n'\n",
        "    str_conf += \"Configuration:\\n\"\n",
        "    str_conf += \"==============\\n\"\n",
        "    str_conf += '\\n'\n",
        "    for key, value in config_dict.items():\n",
        "        str_conf += f\"\\t{key} = {str(value)}\\n\"\n",
        "    str_conf += '\\n'\n",
        "    str_conf += '--------------------------------------------------------------'                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            \n",
        "    return str_conf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZG2pCKjfs5sU"
      },
      "outputs": [],
      "source": [
        "colormaps = ['Greys', 'Greens', 'GnBu', 'Blues', 'Purples', 'PuRd', 'Reds', 'Oranges', 'YlOrBr', \n",
        "            'YlOrRd', 'OrRd', 'RdPu', 'BuPu',\n",
        "            'PuBu', 'YlGnBu', 'PuBuGn', 'BuGn', 'YlGn']\n",
        "colormaps_layers = ['Greys', 'Greens', 'YlGn', 'PuBuGn', 'GnBu', 'Blues',\n",
        "             'Purples', 'RdPu', 'PuRd', 'Oranges', 'OrRd', 'Reds', 'YlOrRd', 'BuPu',\n",
        "            'YlGnBu','BuGn', 'PuBu', 'YlOrBr']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5-ylETBpdQlF"
      },
      "outputs": [],
      "source": [
        "n_layers = 12\n",
        "n_heads = 12"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NISnUnjVBboo"
      },
      "source": [
        "#### Directories and files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3SQlM1w0aqoy"
      },
      "outputs": [],
      "source": [
        "main_dir = '/content/drive/My Drive/Dottorato/Bio/Transformer_variations'\n",
        "\n",
        "# Input data:\n",
        "datasets_dir = '/content/drive/My Drive/tesi/datasets'\n",
        "variant_files = {}\n",
        "for filename in os.listdir(Path(datasets_dir) / 'original'):\n",
        "    variant_files[os.path.splitext(filename)[0]] = Path(datasets_dir) / 'original' / filename\n",
        "if config_dict['SPIKE_REGION_ANALYSIS']:\n",
        "    reference_seq_file = Path(datasets_dir) / 'reference.fasta'\n",
        "    if not os.path.exists(reference_seq_file):\n",
        "        raise FileNotFoundError(f'File {reference_seq_file} not found in {datasets_dir} folder.')\n",
        "\n",
        "# Experiment dir:\n",
        "if config_dict['SPLIT_DATA_IN_CHUNKS']:\n",
        "    experiment_dir = Path(main_dir) / f\"cl{config_dict['CHUNK_LEN']}_cs{config_dict['CHUNK_STRIDE']}_k{config_dict['K']}_s{config_dict['STRIDE']}\"\n",
        "else:\n",
        "    experiment_dir = Path(main_dir) / f\"k{config_dict['K']}_s{config_dict['STRIDE']}\"\n",
        "\n",
        "# Preprocessed data:\n",
        "preprocessed_data_dir = Path(experiment_dir) / 'preprocessed_data'\n",
        "if not os.path.exists(preprocessed_data_dir):\n",
        "    os.makedirs(preprocessed_data_dir)\n",
        "    print(f\"Directory '{preprocessed_data_dir}' created\")\n",
        "if config_dict['SPIKE_REGION_ANALYSIS']:\n",
        "    reformatted_seqs_file = Path(preprocessed_data_dir) / 'reformatted_seqs.fasta'\n",
        "    duplicated_seqs_file = Path(preprocessed_data_dir) / 'duplicated_seqs.fasta'\n",
        "    aligned_seqs_file = Path(preprocessed_data_dir) / 'aligned.sam'\n",
        "    spike_seqs_file = Path(preprocessed_data_dir) / 'spike_seqs.csv'\n",
        "    cigars_file = Path(preprocessed_data_dir) / 'cigars.csv'\n",
        "    input_seqs_file = spike_seqs_file\n",
        "else:\n",
        "    reformatted_seqs_file = Path(preprocessed_data_dir) / 'reformatted_seqs.csv'\n",
        "    input_seqs_file = reformatted_seqs_file\n",
        "seqs_index_file = Path(preprocessed_data_dir) / 'seqs_index.csv'\n",
        "ids_dict_file = Path(preprocessed_data_dir) / 'ids_dict.csv'\n",
        "trainvaltest_splits_dir = Path(preprocessed_data_dir) / 'trainvaltest_splits'\n",
        "train_file = Path(trainvaltest_splits_dir) / 'train.csv'\n",
        "val_file = Path(trainvaltest_splits_dir) / 'val.csv'\n",
        "test_file = Path(trainvaltest_splits_dir) / 'test.csv'\n",
        "trainvaltest_sizes_file = Path(trainvaltest_splits_dir) / 'trainvaltest_sizes.csv'\n",
        "token_count_file = Path(preprocessed_data_dir) / 'token_count.csv'\n",
        "\n",
        "# Outputs dir:\n",
        "outputs_dir = Path(experiment_dir) / 'outputs'\n",
        "if not os.path.exists(outputs_dir):\n",
        "    os.makedirs(outputs_dir)\n",
        "    print(f\"Directory '{outputs_dir}' created\")\n",
        "log_dir = Path(outputs_dir) / 'log'\n",
        "if not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir)\n",
        "    print(f\"Directory '{log_dir}' created\")\n",
        "tokens_histograms_dir = Path(outputs_dir) / 'tokens_histograms'\n",
        "if not os.path.exists(tokens_histograms_dir):\n",
        "    os.makedirs(tokens_histograms_dir)\n",
        "    print(f\"Directory '{tokens_histograms_dir}' created\")\n",
        "final_val_outputs_file = Path(outputs_dir) / 'final_val_outputs'\n",
        "final_test_outputs_file = Path(outputs_dir) / 'final_test_outputs'\n",
        "model_file_finetuned = Path(outputs_dir) / 'model_finetuned'\n",
        "model_file = Path(outputs_dir) / 'model'\n",
        "tokenizer_dir = Path(outputs_dir) / 'tokenizer'\n",
        "training_stats_file = Path(outputs_dir) / 'training_stats'\n",
        "test_accuracies_file = Path(outputs_dir) / 'test_accuracies'\n",
        "final_data_test_file = Path(outputs_dir) / 'final_data_test_file'\n",
        "\n",
        "# attention matrices\n",
        "attention_matrices_dir = Path(outputs_dir) / 'attention_matrices'\n",
        "if not os.path.exists(attention_matrices_dir):\n",
        "    os.makedirs(attention_matrices_dir)\n",
        "    print(f\"Directory '{attention_matrices_dir}' created\")\n",
        "proportion_attn_domains_dir = Path(attention_matrices_dir) / \"proportion_attn_domains\"\n",
        "if not os.path.exists(proportion_attn_domains_dir):\n",
        "    os.makedirs(proportion_attn_domains_dir)\n",
        "    print(f\"Directory '{proportion_attn_domains_dir}' created\")\n",
        "\n",
        "#mathematical interpretation outputs\n",
        "math_interpret_dir = Path(outputs_dir) / \"mathematical_interpretation\"\n",
        "if not os.path.exists(math_interpret_dir):\n",
        "    os.makedirs(math_interpret_dir)\n",
        "    print(f\"Directory '{math_interpret_dir}' created\")\n",
        "CLS_embeddings_dir = Path(math_interpret_dir) / \"Y_outputs\" / \"CLS_embeddings\"\n",
        "if not os.path.exists(CLS_embeddings_dir):\n",
        "    os.makedirs(CLS_embeddings_dir)\n",
        "    print(f\"Directory '{CLS_embeddings_dir}' created\")\n",
        "\n",
        "# biological interpretation output\n",
        "log_dir_bio = Path(outputs_dir) / \"biological_interpretation\" / \"log\"\n",
        "if not os.path.exists(log_dir_bio):\n",
        "    os.makedirs(log_dir_bio)\n",
        "    print(f\"Directory '{log_dir_bio}' created\")\n",
        "\n",
        "# clustering output\n",
        "clustering_dir = Path(outputs_dir) / \"clustering\"\n",
        "if not os.path.exists(clustering_dir):\n",
        "    os.makedirs(clustering_dir)\n",
        "    print(f\"Directory '{clustering_dir}' created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8iK6he4kTgp_"
      },
      "outputs": [],
      "source": [
        "config_dict['CLASS_LABELS'] = {} \n",
        "i = 0\n",
        "for variant_name in variant_files:\n",
        "    config_dict['CLASS_LABELS'][variant_name] = i\n",
        "    i += 1\n",
        "config_dict['N_CLASSES'] = i\n",
        "inv_class_labels_dict = {v:k for k, v in config_dict['CLASS_LABELS'].items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAl_Nz-Nw-bO"
      },
      "outputs": [],
      "source": [
        "n_log_files = len(os.listdir(log_dir))\n",
        "if n_log_files > 0:\n",
        "    log_file = Path(log_dir) / f'log({n_log_files}).txt'\n",
        "else:\n",
        "    log_file = Path(log_dir) / f'log.txt'\n",
        "\n",
        "with open(log_file, 'w') as log_fp:\n",
        "    log_fp.write(generate_config_str())\n",
        "    print(generate_config_str())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d49fkRvRBqVx"
      },
      "source": [
        "#### Tokenizer and Bert model setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0lESROX9zqI"
      },
      "outputs": [],
      "source": [
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=True)\n",
        "tokenizer = AutoTokenizer.from_pretrained(tokenizer_dir)\n",
        "\n",
        "model_base = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-cased\", \n",
        "    num_labels=config_dict['N_CLASSES'],\n",
        "    output_attentions = True, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        ")\n",
        "model_base.cuda()\n",
        "\n",
        "model_finetuned = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-cased\", \n",
        "    num_labels=config_dict['N_CLASSES'],\n",
        "    output_attentions = True, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = True, # Whether the model returns all hidden-states.\n",
        ")\n",
        "model_finetuned.resize_token_embeddings(len(tokenizer))\n",
        "model_finetuned.cuda()\n",
        "model_finetuned.load_state_dict(torch.load(model_file_finetuned))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOOTHxRydWym"
      },
      "outputs": [],
      "source": [
        "if config_dict['USE_GPU'] and (do_training or do_test or config_dict['TASK_TYPE']=='one_vs_all_classification'):\n",
        "    # Get the GPU device name.\n",
        "    device_name = tf.test.gpu_device_name()\n",
        "\n",
        "    # The device name should look like the following:\n",
        "    if device_name == '/device:GPU:0':\n",
        "        print('Found GPU at: {}'.format(device_name))\n",
        "    else:\n",
        "        raise SystemError('GPU device not found')\n",
        "\n",
        "\n",
        "    # If there's a GPU available...\n",
        "    if torch.cuda.is_available():    \n",
        "        # Tell PyTorch to use the GPU.    \n",
        "        device = torch.device(\"cuda\")\n",
        "        print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "        print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "    # If not...\n",
        "    else:\n",
        "        print('No GPU available, using the CPU instead.')\n",
        "        device = torch.device(\"cpu\")\n",
        "\n",
        "# elif USE_TPU:\n",
        "#     try:\n",
        "#         tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "#         print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "#     except ValueError:\n",
        "#         raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "else:\n",
        "    print('Runtime type: None.')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer.save_pretrained(tokenizer_file)"
      ],
      "metadata": {
        "id": "wJwKrFxDqUPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-_ek6Bf8PK0"
      },
      "outputs": [],
      "source": [
        "# Tell pytorch to run this model on the GPU.\n",
        "if do_training:\n",
        "    model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh8B3bjtS4LO"
      },
      "source": [
        "### Supervised: BERT classifier\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjMdI11yAMmG"
      },
      "source": [
        "####Training functions (fonti: [esempio1](https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_multi_label_classification.ipynb), [esempio2](https://colab.research.google.com/drive/1pTuQhug6Dhl9XalKB0zUGf4FIdYFlpcX#scrollTo=6O_NbXFGMukX))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UjgcRrvJIa5-"
      },
      "outputs": [],
      "source": [
        "class ClearMemory(Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        gc.collect()\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
        "\n",
        "def setup_training(train_data_size, log_fp):\n",
        "    # Set up epochs and steps\n",
        "    steps_per_epoch = int(train_data_size / config_dict['TRAIN_BATCH_SIZE'])\n",
        "    num_train_steps = steps_per_epoch * config_dict['EPOCHS']\n",
        "    warmup_steps = int(config_dict['EPOCHS'] * train_data_size * 0.1 / config_dict['TRAIN_BATCH_SIZE'])\n",
        "\n",
        "    # creates an optimizer and learning rate scheduler\n",
        "    optimizer = torch.optim.AdamW(model.parameters(),\n",
        "                  lr = config_dict['LR'], # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = warmup_steps, \n",
        "                                            num_training_steps = num_train_steps)\n",
        "    # optimizer = nlp.optimization.create_optimizer(\n",
        "    #     2e-5, num_train_steps=num_train_steps, num_warmup_steps=warmup_steps)\n",
        "\n",
        "    # Set the seed value all over the place to make this reproducible.\n",
        "    seed_val = 42\n",
        "    torch.manual_seed(seed_val)\n",
        "    torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "    log_fp.write(\"\\nTraining setup:\\n\")\n",
        "    log_fp.write(\"===============\\n\")\n",
        "    log_fp.write(f\"\\tsteps_per_epoch = {steps_per_epoch}\\n\")\n",
        "    log_fp.write(f\"\\tnum_train_steps = {num_train_steps}\\n\")\n",
        "    log_fp.write(f\"\\twarmup_steps = {warmup_steps}\\n\")\n",
        "    log_fp.write(f\"\\toptimizer = {optimizer}\\n\")\n",
        "    log_fp.write(f\"\\tscheduler = {scheduler}\\n\")\n",
        "    log_fp.write(f\"\\tseed_val = {seed_val}\\n\")\n",
        "    \n",
        "    return optimizer, scheduler\n",
        "\n",
        "def loss_fn(outputs, targets):\n",
        "    if config_dict['N_CLASSES'] > 2:\n",
        "        criterion = torch.nn.CrossEntropyLoss()\n",
        "        return criterion(outputs.logits, targets.to(torch.long))\n",
        "    else:\n",
        "        return outputs.loss\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZK9-HCP7IhuQ"
      },
      "source": [
        "Training and validation functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17o-i3hgM3sA"
      },
      "outputs": [],
      "source": [
        "def train(train_dataloader, optimizer, scheduler, log_fp):\n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "    train_steps_loss = []\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader, 0):\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        ids = batch['ids'].to(device, dtype = torch.long)\n",
        "        mask = batch['mask'].to(device, dtype = torch.long)\n",
        "        targets = batch['targets'].to(device, dtype = torch.float)\n",
        "        seq_ids = batch['seq_ids'].to(device, dtype = torch.int)\n",
        "        y_onehot = torch.nn.functional.one_hot(targets.long(), num_classes=config_dict['N_CLASSES'])\n",
        "        y_onehot = y_onehot.float()\n",
        "            \n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad() \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # In PyTorch, calling `model` will in turn call the model's `forward` \n",
        "        # function and pass down the arguments. The `forward` function is \n",
        "        # documented here: \n",
        "        # https://huggingface.co/transformers/model_doc/bert.html#bertforsequenceclassification\n",
        "        # The results are returned in a results object, documented here:\n",
        "        # https://huggingface.co/transformers/main_classes/output.html#transformers.modeling_outputs.SequenceClassifierOutput\n",
        "        # Specifically, we'll get the loss (because we provided labels) and the\n",
        "        # \"logits\"--the model outputs prior to activation.\n",
        "        outputs = model(ids, \n",
        "                       token_type_ids=None, \n",
        "                       attention_mask=mask, \n",
        "                       labels=y_onehot,\n",
        "                       return_dict=True)\n",
        "\n",
        "        loss = loss_fn(outputs, targets)\n",
        "\n",
        "        # Save hidden states of last layer for clustering\n",
        "        # hidden_states = Tuple of torch.FloatTensor (one for the output of the embeddings\n",
        "        # + one for the output of each layer) of shape (batch_size, sequence_length, hidden_size).\n",
        "        # last_hidden_states = outputs.hidden_states[12]\n",
        "        \n",
        "        # Progress update every 40 batches.\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            # Report progress.\n",
        "            print('  Batch {:>5}  of  {:>5}.    Elapsed: {:}.     Loss:  {:}.'.format(step, len(train_dataloader), elapsed, loss.item()))\n",
        "            log_fp.write(('  Batch {:>5}  of  {:>5}.    Elapsed: {:}.     Loss:  {:}.\\n'.format(step, len(train_dataloader), elapsed, loss.item())))\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        total_train_loss += float(loss.item())\n",
        "        if step % 50 == 0 and not step == 0:\n",
        "            train_steps_loss.append(float(loss.item()))\n",
        "        \n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        \n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))\n",
        "    log_fp.write(\"  Average training loss: {0:.2f}\\n\".format(avg_train_loss))\n",
        "    log_fp.write(\"  Training epoch took: {:}\\n\".format(training_time))\n",
        "\n",
        "    return avg_train_loss, training_time, train_steps_loss\n",
        "\n",
        "\n",
        "def validation(val_dataloader, log_fp):\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    final_data = {'seq_ids' : [],\n",
        "                  'positions' : [],\n",
        "                  'targets' : [],\n",
        "                  'outputs' : [],\n",
        "                  'last_hidden_states_dict' : {}\n",
        "                  }\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        ids = batch['ids'].to(device, dtype = torch.long)\n",
        "        mask = batch['mask'].to(device, dtype = torch.long)\n",
        "        targets = batch['targets'].to(device, dtype = torch.float)\n",
        "        seq_ids = batch['seq_ids'].to('cpu').numpy()\n",
        "        positions = batch['positions'].to('cpu').numpy()\n",
        "\n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            y_onehot = torch.nn.functional.one_hot(targets.long(), num_classes=config_dict['N_CLASSES'])\n",
        "            y_onehot = y_onehot.float()\n",
        "            outputs = model(ids,  \n",
        "                            attention_mask=mask,\n",
        "                            labels=y_onehot,\n",
        "                            return_dict=True)\n",
        "            \n",
        "        # Get the loss and \"logits\" output by the model. The \"logits\" are the \n",
        "        # output values prior to applying an activation function like the \n",
        "        # softmax.\n",
        "        loss = loss_fn(outputs, targets)\n",
        "        logits = outputs.logits\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += float(loss.item())\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = targets.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        final_data['targets'].extend(y_onehot.cpu().detach().numpy().tolist())\n",
        "        if config_dict['N_CLASSES'] > 2:\n",
        "            final_data['outputs'].extend(torch.softmax(outputs.logits, dim=1).cpu().detach().numpy().tolist())\n",
        "        else:\n",
        "            final_data['outputs'].extend(torch.sigmoid(outputs.logits).cpu().detach().numpy().tolist())\n",
        "        final_data['seq_ids'].extend(seq_ids)\n",
        "        final_data['positions'].extend(positions)\n",
        "\n",
        "        # Save hidden states of last layer for clustering\n",
        "        # hidden_states = Tuple of torch.FloatTensor (one for the output of the embeddings\n",
        "        # + one for the output of each layer) of shape (batch_size, sequence_length, hidden_size).\n",
        "        last_hidden_states = outputs.hidden_states[12].cpu().detach().numpy()\n",
        "        for i, seq_id in enumerate(seq_ids):\n",
        "            final_data['last_hidden_states_dict']['seq_id'] = last_hidden_states[i]\n",
        "\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Validation Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "    log_fp.write(\"  Validation Accuracy: {0:.2f}\\n\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "    log_fp.write(\"  Validation Loss: {0:.2f}\\n\".format(avg_val_loss))\n",
        "    log_fp.write(\"  Validation took: {:}\\n\".format(validation_time))\n",
        "\n",
        "    return final_data, avg_val_loss, avg_val_accuracy, validation_time\n",
        "\n",
        "\n",
        "def supervisedBertClassifierFinetune(train_dataloader, val_dataloader, train_data_size, log_fp):\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    optimizer, scheduler = setup_training(train_data_size, log_fp)\n",
        "\n",
        "    training_stats = []\n",
        "    train_steps_loss = []\n",
        "    total_t0 = time.time()\n",
        "    log_fp.write(\"\\nTraining and validation:\\n\")\n",
        "    log_fp.write(\"==========================\\n\")\n",
        "\n",
        "    for epoch in range(config_dict['EPOCHS']):\n",
        "        print(\"\")\n",
        "        print('======== Epoch {:} / {:} ========'.format(epoch + 1, config_dict['EPOCHS']))\n",
        "        print('Training...')\n",
        "        log_fp.write('\\n======== Epoch {:} / {:} ========\\n'.format(epoch + 1, config_dict['EPOCHS']))\n",
        "        log_fp.write(\"\\nTraining:\\n\")\n",
        "        avg_train_loss, training_time, train_steps_loss_epoch = train(train_dataloader, optimizer, scheduler, log_fp)\n",
        "        train_steps_loss.extend(train_steps_loss_epoch)\n",
        "\n",
        "        print(\"\")\n",
        "        print(\"Validation...\")\n",
        "        log_fp.write(\"\\nValidation:\\n\")\n",
        "        final_data, avg_val_loss, avg_val_accuracy, validation_time = validation(val_dataloader, log_fp)\n",
        "\n",
        "        training_stats_epoch = {\n",
        "            'epoch': epoch + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time,\n",
        "            'final_data':final_data\n",
        "        }\n",
        "        training_stats.append(training_stats_epoch)\n",
        "\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Training complete!\")\n",
        "\n",
        "    print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))\n",
        "    log_fp.write(\"Total training took {:} (h:mm:ss)\\n\".format(format_time(time.time()-total_t0)))\n",
        "\n",
        "    # return train hidden_states from last epoch\n",
        "    return training_stats, train_steps_loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fCYb9yvaE1BL"
      },
      "source": [
        "#### Finetuning\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RAReZQwFVHo0"
      },
      "outputs": [],
      "source": [
        "if do_training and do_finetuning:\n",
        "    with open(train_file) as train_fp, open(val_file) as val_fp, open(log_file, 'a') as log_fp:\n",
        "\n",
        "        train_reader = csv.reader(train_fp, delimiter=',')\n",
        "        train_metadata = {'len':sizes_info['train_data_size_seqs']}\n",
        "        X_train_generator = DatasetGenerator(train_reader, train_fp, train_metadata) \n",
        "        train_dataloader = DataLoader(\n",
        "                X_train_generator,  # The training samples.\n",
        "                sampler = RandomSampler(X_train_generator), # Select batches randomly\n",
        "                batch_size = config_dict['TRAIN_BATCH_SIZE'], # Trains with this batch size.\n",
        "                num_workers = 0\n",
        "        )\n",
        "        \n",
        "        val_reader = csv.reader(val_fp, delimiter=',')\n",
        "        val_metadata = {'len':sizes_info['val_data_size_seqs']}\n",
        "        X_val_generator = DatasetGenerator(val_reader, val_fp, val_metadata) #.batch(EVAL_BATCH_SIZE)\n",
        "\n",
        "        \n",
        "        validation_dataloader = DataLoader(\n",
        "                X_val_generator, # The validation samples.\n",
        "                sampler = SequentialSampler(X_val_generator), # Pull out batches sequentially.\n",
        "                batch_size = config_dict['EVAL_BATCH_SIZE'], # Evaluate with this batch size.\n",
        "                num_workers = 0\n",
        "        )\n",
        "\n",
        "        training_stats, train_steps_loss = supervisedBertClassifierFinetune(train_dataloader, validation_dataloader, sizes_info['train_data_size_seqs'], log_fp)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8qTYoZYl7xy"
      },
      "source": [
        "#### Save model and outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bNMO8WVnyqAE"
      },
      "outputs": [],
      "source": [
        "# save or load model for inference:\n",
        "if do_training or do_test or config_dict['TASK_TYPE']=='one_vs_all_classification':\n",
        "    if do_finetuning:\n",
        "        mod_f = model_file_finetuned\n",
        "    else:\n",
        "        mod_f = model_file\n",
        "    if os.path.exists(mod_f):\n",
        "        # model.load_state_dict(torch.load(mod_f, map_location=torch.device('cpu')))\n",
        "        # device = torch.device(\"cpu\")\n",
        "        model_finetuned.load_state_dict(torch.load(mod_f))\n",
        "    else:\n",
        "        torch.save(model_finetuned.state_dict(), mod_f)\n",
        "\n",
        "if do_test or config_dict['TASK_TYPE']=='one_vs_all_classification':\n",
        "    model_finetuned.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmIVTEGD_y19"
      },
      "outputs": [],
      "source": [
        "# # save or load last epoch validation data:\n",
        "# if os.path.exists(final_val_outputs_file):\n",
        "#     final_data = pickle.load(open(final_val_outputs_file, 'rb'))\n",
        "# else:         \n",
        "#     final_data = training_stats[-1]['final_data']\n",
        "#     # save output data on file for furure computation:\n",
        "#     pickle.dump(final_data, open(final_val_outputs_file, 'wb'))\n",
        "#     # pickle.dump(str(final_data), open(final_val_outputs_file, 'wb'))\n",
        "\n",
        "\n",
        "# # save or load last epoch validation data:\n",
        "# if os.path.exists(training_stats_file):\n",
        "#     training_stats = pickle.load(open(training_stats_file, 'rb'))\n",
        "# else:         \n",
        "#     # save output data on file for furure computation:\n",
        "#     pickle.dump(training_stats, open(training_stats_file, 'wb'))\n",
        "#     # pickle.dump(str(final_data), open(final_val_outputs_file, 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51iQ6z5tfd2G"
      },
      "source": [
        "#### Validation statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJy0DrxgkwVN"
      },
      "source": [
        "Cluster last hidden states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1ELwLhBkvst"
      },
      "outputs": [],
      "source": [
        "# from sklearn.manifold import TSNE\n",
        "# import matplotlib.pyplot as plt # graphs plotting\n",
        "# import matplotlib.cm as cm\n",
        "# import seaborn as sns\n",
        "\n",
        "# print(\"Starting t-SNE\")\n",
        "\n",
        "# X_embedded = TSNE(n_components = 2, perplexity = 30, random_state = 1).fit_transform()\n",
        "\n",
        "# print(\"Writting File!!!\")\n",
        "\n",
        "# write_path_11 = \"/alina-data1/sarwan/IEEE_BigData/Dataset/t_sne_plot_2_dim.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eXM0LRUmVAR"
      },
      "source": [
        "Statistics and plots functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YQrkHYfqpnjk"
      },
      "outputs": [],
      "source": [
        "from pandas._config import config\n",
        "def show_train_stats_and_plots(training_stats, train_steps_loss):\n",
        "    print('Results:')\n",
        "    # Display floats with two decimal places.\n",
        "    pd.set_option('precision', 2)\n",
        "\n",
        "    # Create a DataFrame from our training statistics.\n",
        "    df_stats = pd.DataFrame(data=training_stats)\n",
        "\n",
        "    # Use the 'epoch' as the row index.\n",
        "    df_stats = df_stats.set_index('epoch')\n",
        "\n",
        "    # A hack to force the column headers to wrap.\n",
        "    #df = df.style.set_table_styles([dict(selector=\"th\",props=[('max-width', '70px')])])\n",
        "\n",
        "    # Display the table.\n",
        "    print(df_stats)\n",
        "\n",
        "    # Use plot styling from seaborn.\n",
        "    sns.set(style='darkgrid')\n",
        "\n",
        "    # Increase the plot size and font size.\n",
        "    sns.set(font_scale=1.5)\n",
        "    fig = plt.figure(1, figsize=(12,6))\n",
        "    #plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "    # Plot the learning curve.\n",
        "    plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "    plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "    # Label the plot.\n",
        "    plt.title(\"Average Training & Validation Loss\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "    plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "    plt.show() \n",
        "    fig_path = Path(outputs_dir) / 'trainval.jpg'\n",
        "    fig.savefig(fig_path)  \n",
        "\n",
        "    fig2 = plt.figure(2, figsize=(30,6))\n",
        "    plt.plot(train_steps_loss, 'b', label=\"Training steps loss (every 40 steps)\")\n",
        "\n",
        "    # Label the plot.\n",
        "    plt.title(\"Training steps loss\")\n",
        "    plt.xlabel(\"Step\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show() \n",
        "    fig_path2 = Path(outputs_dir) / 'train_steps.jpg'\n",
        "    fig2.savefig(fig_path2)  \n",
        "\n",
        "\n",
        "def confusion_matrix_plot(targets_labels, outputs_labels, path, taskname = \"\"):\n",
        "    confusion_matr = metrics.confusion_matrix(targets_labels, outputs_labels)\n",
        "    plt.figure()\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    sns.heatmap(confusion_matr, annot=True, fmt=\"d\", cmap=\"viridis\", annot_kws={\"fontsize\":20})\n",
        "    plt.title(f'{taskname} Confusion Matrix', fontsize=25)\n",
        "    plt.ylabel('True label', fontsize=21)\n",
        "    plt.xlabel('Predicted label', fontsize=21)\n",
        "    curr_xticks, curr_xlabels = plt.xticks()\n",
        "    plt.xticks(curr_xticks, labels=[inv_class_labels_dict[int(t.get_text())] for t in curr_xlabels], rotation=90, fontsize=20)\n",
        "    curr_yticks, curr_ylabels = plt.yticks()\n",
        "    plt.yticks(curr_yticks, labels=[inv_class_labels_dict[int(t.get_text())] for t in curr_ylabels], rotation=0, fontsize=20)\n",
        "    cax = plt.gcf().axes[-1]\n",
        "    cax.tick_params(labelsize=20)\n",
        "    fig_path = Path(path) / f\"{taskname.replace(' ', '_')}_confusion_matrix.jpg\"\n",
        "    fig = plt.gcf()\n",
        "    fig.savefig(fig_path)\n",
        "    plt.show()\n",
        "    plt.figure()\n",
        "\n",
        "\n",
        "def plot_PRC(y, y_score, y_pred, path):\n",
        "    fig = plt.figure(figsize=(8,8))\n",
        "    ax = fig.gca()\n",
        "    ax.set_xlim([-0.1, 1.1])\n",
        "    ax.set_ylim([-0.1, 1.1])\n",
        "    ax.grid(True)\n",
        "    ax.set_aspect('equal')\n",
        "    ax.legend(loc='lower right')\n",
        "    ax.set_title(f\"Precision-Recall Curves\")\n",
        "    # metrics.PrecisionRecallDisplay.from_predictions(y, y_score, ax=ax, )\n",
        "    # precision = dict()\n",
        "    # recall = dict()\n",
        "    # average_precision = dict()\n",
        "    # for i in range(config_dict['N_CLASSES']):\n",
        "    #     precision[i], recall[i], _ = metrics.precision_recall_curve(y[:],\n",
        "    #                                                         y_score[:, i])\n",
        "    #     average_precision[i] = metrics.average_precision_score(y[:], y_score[:, i])\n",
        "\n",
        "    # A \"micro-average\": quantifying score on all classes jointly\n",
        "    # precision[\"micro\"], recall[\"micro\"], _ = metrics.precision_recall_curve(y,\n",
        "    #     y_score)\n",
        "    # average_precision[\"micro\"] = metrics.average_precision_score(y, y_score,\n",
        "    #                                                     average=\"micro\")\n",
        "    # print('Average precision score, micro-averaged over all classes: {0:0.2f}'\n",
        "    #     .format(average_precision[\"micro\"]))\n",
        "    # display = metrics.PrecisionRecallDisplay(\n",
        "    #     recall=recall[\"micro\"],\n",
        "    #     precision=precision[\"micro\"],\n",
        "    #     average_precision=average_precision[\"micro\"])\n",
        "    # display.plot()\n",
        "    # _ = display.ax_.set_title(f\"Precision-Recall curve micro-averaged over all classes (AP={average_precision['micro']})\")\n",
        "    def multiclass_prc(y_test, y_score, y_pred, average=\"micro\"):\n",
        "        lb = LabelBinarizer()\n",
        "        lb.fit(y_test)\n",
        "        y_test = lb.transform(y_test)\n",
        "        y_pred = lb.transform(y_pred)\n",
        "\n",
        "        for (idx, c_label) in enumerate(config_dict['CLASS_LABELS'].keys()):\n",
        "            display = metrics.PrecisionRecallDisplay.from_predictions(y_test[:,idx].astype(int), y_pred[:,idx], name=c_label)\n",
        "            display.plot(ax=ax)\n",
        "        # ax.plot(fpr, fpr, 'b-', label = 'Random Guessing')\n",
        "        return metrics.average_precision_score(y_test, y_pred, average=average)\n",
        "    print('AP score:', multiclass_prc(y, y_score, y_pred))\n",
        "    ax.set_xlabel('Recall')\n",
        "    ax.set_ylabel('Precision')\n",
        "    # fig.show()\n",
        "    fig.savefig(Path(path) / 'prc.png')\n",
        "\n",
        "def ROC_curve_plot(targets_labels, outputs_labels, path, taskname = \"\", figsize=(17, 6)):\n",
        "    fpr = dict()\n",
        "    tpr = dict()\n",
        "    roc_auc = dict()\n",
        "    labels_dict = {class_label:[[],[]] for class_label in config_dict['CLASS_LABELS'].values()}\n",
        "    for i in range(len(targets_labels)):\n",
        "        labels_dict[targets_labels[i]][0].append(targets_labels[i])\n",
        "        labels_dict[targets_labels[i]][1].append(outputs_labels[i])\n",
        "\n",
        "    for class_label, tgt_out_labels in labels_dict.items():\n",
        "        print(\"CLASSSSS\")\n",
        "        print(class_label)\n",
        "        print(tgt_out_labels[0])\n",
        "        print(tgt_out_labels[1])\n",
        "        fpr[class_label], tpr[class_label], _ = metrics.roc_curve(tgt_out_labels[0], tgt_out_labels[1], pos_label=class_label)\n",
        "        roc_auc[class_label] = metrics.auc(fpr[class_label], tpr[class_label])\n",
        "\n",
        "    # roc for each class\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    ax.plot([0, 1], [0, 1], 'k--')\n",
        "    ax.set_xlim([0.0, 1.0])\n",
        "    ax.set_ylim([0.0, 1.05])\n",
        "    ax.set_xlabel('False Positive Rate')\n",
        "    ax.set_ylabel('True Positive Rate')\n",
        "    ax.set_title('Receiver operating characteristic example')\n",
        "    for class_label in labels_dict.keys():\n",
        "        ax.plot(fpr[class_label], tpr[class_label], label='ROC curve (AUC = %0.2f) for class %i' % (roc_auc[class_label], class_label))\n",
        "    ax.legend(loc=\"best\")\n",
        "    ax.grid(alpha=.4)\n",
        "    sns.despine()\n",
        "    plt.show()\n",
        "\n",
        "def final_statistics(target_labels, output_labels, output_logits, log_file, taskname, logits=None, target_names=None):\n",
        "    accuracy = metrics.accuracy_score(target_labels, output_labels)\n",
        "    f1_score_micro = metrics.f1_score(target_labels, output_labels, average='micro')\n",
        "    f1_score_macro = metrics.f1_score(target_labels, output_labels, average='macro')\n",
        "    if target_names==None:\n",
        "        target_names = config_dict['CLASS_LABELS']\n",
        "    specificity = {}\n",
        "    for l_name, l in target_names.items():\n",
        "        prec,recall,_,_ = metrics.precision_recall_fscore_support(target_labels==l,\n",
        "                                                        output_labels==l,\n",
        "                                                        pos_label=True,average=None)\n",
        "        specificity[l_name] = recall[0] \n",
        "    classification_report = metrics.classification_report(target_labels, output_labels, target_names=target_names.keys())\n",
        "    confusion_matr = metrics.confusion_matrix(target_labels, output_labels)\n",
        "    print(f'{taskname}:')\n",
        "    print(f\"===============================\")\n",
        "    print(f\"Accuracy Score = {accuracy}\")\n",
        "    print(f\"F1 Score (Micro) = {f1_score_micro}\")\n",
        "    print(f\"F1 Score (Macro) = {f1_score_macro}\")\n",
        "    print(f\"Specificity:\\n{json.dumps(specificity, indent=4)}\\n\")\n",
        "    print(f\"Classification report:\\n{str(classification_report)}\")\n",
        "    confusion_matrix_plot(target_labels, output_labels, outputs_dir, taskname)\n",
        "    # plot_PRC(target_labels, output_logits, output_labels, outputs_dir)\n",
        "    with open(log_file, 'a') as log_fp:\n",
        "        log_fp.write(f\"\\n{taskname}:\\n\")\n",
        "        log_fp.write(f\"===============================\\n\")\n",
        "        log_fp.write(f\"Accuracy Score = {accuracy}\\n\")\n",
        "        log_fp.write(f\"F1 Score (Micro) = {f1_score_micro}\\n\")\n",
        "        log_fp.write(f\"F1 Score (Macro) = {f1_score_macro}\\n\")\n",
        "        log_fp.write(f\"Classification report:\\n{classification_report}\\n\")\n",
        "        log_fp.write(f\"Specificity:\\n{json.dumps(specificity, indent=4)}\\n\")\n",
        "        log_fp.write(f\"Confusion matrix:\\n{confusion_matr}\\n\")\n",
        "    if logits:\n",
        "        logits_pos_score = [x[target_labels[i]] for i,x in enumerate(logits)]\n",
        "        ROC_curve_plot(target_labels, logits_pos_score, outputs_dir, taskname)\n",
        "\n",
        "def find_best_positions(final_data, min_score=0.8, threshold=0.5):\n",
        "    best_positions = None\n",
        "\n",
        "    outputs_labels=np.argmax(final_data['outputs'],axis=1)\n",
        "    targets_labels=np.argmax(final_data['targets'],axis=1)\n",
        "\n",
        "    # analisys according to position in sequence\n",
        "    final_data['select_pred'] = []\n",
        "    final_data['count_pred'] = []\n",
        "    for target,pred,pred_score in zip(targets_labels,outputs_labels, final_data['outputs']):\n",
        "        # select only predictions which are correct and with score > min_score (*)\n",
        "        final_data['select_pred'].append(int(target == pred and pred_score[np.argmax(pred_score)]>min_score)) \n",
        "        final_data['count_pred'].append(1)\n",
        "    final_data_df = pd.DataFrame(final_data).drop(columns=['outputs', 'targets','seq_ids'])\n",
        "    grouped_df = final_data_df.groupby(['positions']).agg({'select_pred': 'sum', 'count_pred': 'count'})\n",
        "\n",
        "    # for each position, calculate percentage of chunks which satisfy conditions (see (*))\n",
        "    grouped_df['percents'] = grouped_df['select_pred'] / grouped_df['count_pred']\n",
        "    # select only positions which have a percentage of chunks which satisfy conditions (see (*)) > threshold\n",
        "    best_positions = [i for i, perc in enumerate(np.asarray(grouped_df['percents'])) if perc > threshold]\n",
        "\n",
        "    print(f\"Best positions: {best_positions}\")\n",
        "    with open(log_file, 'a') as log_fp:\n",
        "        log_fp.write(f\"\\nBest positions (i.e. those with >{threshold*100}% of chunks with correct prediction and score>{min_score}):\\n\")\n",
        "        log_fp.write(f\"=======================================================================================\\n\")\n",
        "        log_fp.write(f\"{best_positions}\\n\")\n",
        "\n",
        "    plot = grouped_df['percents'].plot.bar(figsize=(20,10))\n",
        "    fig = plot.get_figure()\n",
        "    fig.suptitle(f\"For each position, percentage of chunks with correct prediction and score>{min_score}\", y=0.95, fontsize=20)\n",
        "    plt.yticks(np.arange(0, 1, 0.1))\n",
        "    plt.grid()\n",
        "    plt.axhline(y=threshold, color='r', linestyle='-')\n",
        "    fig_path = Path(outputs_dir) / f\"percent_pos.jpg\"\n",
        "    fig.savefig(fig_path)\n",
        "    plt.show()\n",
        "\n",
        "    return best_positions\n",
        "\n",
        "def per_sample_result_computation(final_data, best_positions, min_score=0.8, taskname='', filter_positions=True, filter_score=True):\n",
        "    targets_dict = {}\n",
        "    preds_dict = {}\n",
        "    for id,target in zip(final_data['seq_ids'],final_data['targets']):\n",
        "        if id not in targets_dict:\n",
        "            targets_dict[id] = np.argmax(target)\n",
        "        if id not in preds_dict:\n",
        "            preds_dict[id] = {'counts':[], 'outputs_label':[], 'prediction': []}\n",
        "\n",
        "\n",
        "    final_data['select_pred'] = []\n",
        "    final_data['outputs_label'] = []\n",
        "    for pos,pred in zip(final_data['positions'],final_data['outputs']):\n",
        "        # select prediction only if it is in best position and if prediction is certain (score>min_score) (*)\n",
        "        if filter_positions:\n",
        "            if filter_score: \n",
        "                final_data['select_pred'].append(int(pos in best_positions and pred[np.argmax(pred)]>min_score))\n",
        "            else:\n",
        "                final_data['select_pred'].append(int(pos in best_positions))\n",
        "        else:\n",
        "            if filter_score: \n",
        "                final_data['select_pred'].append(int(pred[np.argmax(pred)]>min_score))\n",
        "            else:\n",
        "                final_data['select_pred'].append(int(pred[np.argmax(pred)]>0))\n",
        "        final_data['outputs_label'].append(np.argmax(pred))\n",
        "    \n",
        "    final_data_df = pd.DataFrame(final_data)\n",
        "    # filter only selected predictions according to conditions (see (*))\n",
        "    filtered_data_df = final_data_df[final_data_df['select_pred'] > 0]\n",
        "    filtered_data_df = filtered_data_df[['seq_ids','outputs_label']]\n",
        "    grouped_sample_data_df = pd.DataFrame(filtered_data_df).groupby(['seq_ids','outputs_label']).size().reset_index(name='counts')\n",
        "    grouped_sample_data_dict = grouped_sample_data_df.to_dict('list')\n",
        "\n",
        "    for seq_id,output_l,count in zip(grouped_sample_data_dict['seq_ids'], grouped_sample_data_dict['outputs_label'], grouped_sample_data_dict['counts']):\n",
        "        preds_dict[seq_id]['outputs_label'].append(output_l)\n",
        "        preds_dict[seq_id]['counts'].append(count)\n",
        "\n",
        "     \n",
        "    for seq_id in preds_dict.keys():\n",
        "        counts_sorted = preds_dict[seq_id]['counts'].copy()\n",
        "        counts_sorted.sort(reverse=True)\n",
        "        if len(preds_dict[seq_id]['counts'])==0 or (len(counts_sorted)>1 and all(element == counts_sorted[0] for element in counts_sorted)):\n",
        "            preds_dict[seq_id]['prediction'] = 'uncertain'\n",
        "        else:\n",
        "            majority_class_index = np.argmax(preds_dict[seq_id]['counts'])\n",
        "            preds_dict[seq_id]['prediction'] = preds_dict[seq_id]['outputs_label'][majority_class_index]\n",
        "\n",
        "    correct_pred_count = 0\n",
        "    uncertain_pred_count = 0\n",
        "    tot_count = 0\n",
        "    target_labels = []\n",
        "    output_labels = []\n",
        "\n",
        "\n",
        "    with open(log_file, 'a') as log_fp:\n",
        "        for seq_id in targets_dict.keys():\n",
        "            tot_count += 1\n",
        "            if preds_dict[seq_id]['prediction'] == 'uncertain':\n",
        "                uncertain_pred_count += 1\n",
        "            else:\n",
        "                target_labels.append(targets_dict[seq_id])\n",
        "                output_labels.append(preds_dict[seq_id]['prediction'])\n",
        "                if targets_dict[seq_id] == preds_dict[seq_id]['prediction']:\n",
        "                    correct_pred_count += 1\n",
        "            print(f\"seq: {seq_id}\\t target: {targets_dict[seq_id]}\\t predicted: {preds_dict[seq_id]['prediction']}\")\n",
        "            log_fp.write(f\"seq: {seq_id}\\t target: {targets_dict[seq_id]}\\t predicted: {preds_dict[seq_id]['prediction']}\\n\")\n",
        "\n",
        "    final_statistics(target_labels, output_labels, log_file, f\"{taskname} grouped by samples, filter_positions={filter_positions}, filter_score={filter_score}, min_score={min_score}\")\n",
        "    \n",
        "    print(f\"Correct predictions: {correct_pred_count}/{tot_count} -> {correct_pred_count/tot_count}\")\n",
        "    print(f\"Wrong predictions: {tot_count-correct_pred_count-uncertain_pred_count}/{tot_count} -> {(tot_count-correct_pred_count-uncertain_pred_count)/tot_count}\")\n",
        "    print(f\"Uncertain predictions: {uncertain_pred_count}/{tot_count} -> {uncertain_pred_count/tot_count}\")\n",
        "\n",
        "    with open(log_file, 'a') as log_fp:\n",
        "        log_fp.write(f\"Correct predictions: {correct_pred_count}/{tot_count} -> {correct_pred_count/tot_count}\\n\")\n",
        "        log_fp.write(f\"Wrong predictions: {tot_count-correct_pred_count-uncertain_pred_count}/{tot_count} -> {(tot_count-correct_pred_count-uncertain_pred_count)/tot_count}\\n\")\n",
        "        log_fp.write(f\"Uncertain predictions: {uncertain_pred_count}/{tot_count} -> {uncertain_pred_count/tot_count}\\n\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFshYJ6cdQzn"
      },
      "outputs": [],
      "source": [
        "if do_training:\n",
        "    show_train_stats_and_plots(training_stats, train_steps_loss)\n",
        "\n",
        "    output_labels=np.argmax(final_data['outputs'],axis=1)\n",
        "    target_labels=np.argmax(final_data['targets'],axis=1)\n",
        "    final_statistics(target_labels, output_labels, final_data['outputs'], log_file, 'Global Validation')\n",
        "\n",
        "    if config_dict['SPLIT_DATA_IN_CHUNKS']:\n",
        "        #best_positions = find_best_positions(final_data, min_score=0.8, threshold=0.75)\n",
        "        #per_sample_result_computation(final_data, best_positions, taskname=\"Validation\")\n",
        "        per_sample_result_computation(final_data, best_positions, taskname=\"Validation\", filter_positions=True, filter_score=True, min_score=0.8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJWuuDabaE7k"
      },
      "outputs": [],
      "source": [
        "# show_train_stats_and_plots(training_stats, train_steps_loss)\n",
        "\n",
        "# output_labels=np.argmax(final_data['outputs'],axis=1)\n",
        "# target_labels=np.argmax(final_data['targets'],axis=1)\n",
        "# output_logits = final_data['outputs']\n",
        "# final_statistics(target_labels, output_labels, output_logits, log_file, 'Validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PFgDDhbkVBfP"
      },
      "source": [
        "####Attention matrices functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yNMscXlkVANP"
      },
      "outputs": [],
      "source": [
        "def get_attentions(attentions, sample_idx_in_batch, layer=0, attention_head=0, sum=False):\n",
        "  '''\n",
        "  get the particular output for a particular layer and attention head\n",
        "  layer -> 0 to 11\n",
        "  attention_head -> 0 to 11\n",
        "  '''\n",
        "  if sum:\n",
        "    #avg over all attention heads in a layer\n",
        "    return attentions[layer][sample_idx_in_batch].sum(dim=0).cpu().detach().numpy()\n",
        "\n",
        "  #return values for a particular attention head inside a specific layer\n",
        "  return attentions[layer][sample_idx_in_batch][attention_head].cpu().detach().numpy()\n",
        "\n",
        "\n",
        "def min_max_scale(X, range=(0, 1)):\n",
        "    mi, ma = range\n",
        "    X_std = (X - X.min()) / (X.max() - X.min())\n",
        "    X_scaled = X_std * (ma - mi) + mi\n",
        "    return X_scaled\n",
        "\n",
        "\n",
        "# def calculate_weight_domain_proportion_by_head(attentions_sum, domain, proportion, theta=0):\n",
        "#     if domain not in domain_coordinates_1based:\n",
        "#         raise ValueError(\"plt_attentions_domain: domain must be one of %r.\" % domain_coordinates_1based)\n",
        "\n",
        "#     domain_start_idx, domain_end_idx = convert_domain_coords_in_token_indices(domain)\n",
        "\n",
        "#     # proportion of attention weights in the selected domain from each head that connects all amino acids to those in the selected domain\n",
        "#     #weight_total_by_head = torch.zeros((n_layers, n_heads), dtype=torch.double)\n",
        "#     if proportion == \"attention\":\n",
        "#         # Update total attention_analysis weights per head. Sum over from_index (dim 2), to_index (dim 3)\n",
        "#         weight_total_by_head = attentions_sum.sum((2, 3))\n",
        "#         # Update weighted sum of feature values per head\n",
        "#         weight_domain_sum_by_head = attentions_sum[:, :, :, domain_start_idx:domain_end_idx+1].sum((2, 3))\n",
        "#     elif proportion == \"high-confidence-attention\":\n",
        "#         attentions_sum_total_masked = ma.masked_where(attentions_sum <= theta, attentions_sum)\n",
        "#         ma.set_fill_value(attentions_sum_total_masked, 0)\n",
        "#         weight_total_by_head = attentions_sum_total_masked.sum((2, 3))\n",
        "#         attentions_sum_domain = attentions_sum[:, :, :, domain_start_idx:domain_end_idx+1]\n",
        "#         attentions_sum_domain_masked = ma.masked_where(attentions_sum_domain <= theta, attentions_sum_domain)\n",
        "#         ma.set_fill_value(attentions_sum_domain_masked, 0)\n",
        "#         weight_domain_sum_by_head = attentions_sum_domain_masked.sum((2, 3))\n",
        "#     elif proportion == \"high-attention-tokens-count\":\n",
        "#         mask_high_attn_total = attentions_sum > theta\n",
        "#         weight_total_by_head = mask_high_attn_total.long().sum((2, 3))\n",
        "#         mask_high_attn_domain = attentions_sum[:, :, :, domain_start_idx:domain_end_idx+1] > theta\n",
        "#         weight_domain_sum_by_head = mask_high_attn_domain.long().sum((2, 3))\n",
        "#     else:\n",
        "#         raise ValueError(\"plt_attentions_domain: proportion must be one of %r.\" % [\"attention\", \"high-attention-tokens\"])\n",
        "\n",
        "#     return weight_domain_sum_by_head / weight_total_by_head, weight_domain_sum_by_head, weight_total_by_head\n",
        "\n",
        "\n",
        "# def plt_attentions_domain(attentions_sum, domain, dir_path, filename, proportion, theta=0, min_total=0, fig_size=(130,100), title=None):\n",
        "#     if domain not in domain_coordinates_1based:\n",
        "#         raise ValueError(\"plt_attentions_domain: domain must be one of %r.\" % domain_coordinates_1based)\n",
        "\n",
        "#     weight_domain_proportion_by_head, weight_sum, weight_total = calculate_weight_domain_proportion_by_head(attentions_sum, domain, proportion, theta=theta)\n",
        "\n",
        "#     exclude_mask = np.array(weight_total) < min_total\n",
        "#     masked_weight_domain_proportion = np.ma.masked_array(weight_domain_proportion_by_head, mask=exclude_mask)\n",
        "#     layer_max = np.asarray(masked_weight_domain_proportion).max(-1)\n",
        "\n",
        "#     fig = plt.figure(figsize=(5, 3.5)) #plt.figure(figsize=(3, 2.2))\n",
        "#     fig.suptitle(title, fontsize=13, fontweight='bold')\n",
        "#     ax1 = plt.subplot2grid((100, 85), (0, 0), colspan=65, rowspan=99)  # Heatmap\n",
        "#     ax2 = plt.subplot2grid((100, 85), (12, 70), colspan=15, rowspan=75)  # Barchart\n",
        "\n",
        "#     xtick_labels = [str(i) if i % 2 == 0 else '' for i in range(1, n_heads + 1)]\n",
        "#     ytick_labels = [str(i) if i % 2 == 0 else '' for i in range(1, n_layers + 1)]\n",
        "#     heatmap = sns.heatmap((masked_weight_domain_proportion * 100).tolist(), center=0.0, ax=ax1,\n",
        "#                           square=True, cbar=False, linewidth=0.1, linecolor='#D0D0D0',\n",
        "#                           cmap=LinearSegmentedColormap.from_list('rg', [\"#F14100\", \"white\", \"#5a3dc4\"], N=256),\n",
        "#                           mask=exclude_mask,\n",
        "#                           xticklabels=xtick_labels,\n",
        "#                           yticklabels=ytick_labels)\n",
        "#     for _, spine in heatmap.spines.items():\n",
        "#         spine.set_visible(True)\n",
        "#         spine.set_edgecolor('#D0D0D0')\n",
        "#         spine.set_linewidth(0.1)\n",
        "#     plt.setp(heatmap.get_yticklabels(), fontsize=11)\n",
        "#     plt.setp(heatmap.get_xticklabels(), fontsize=11)\n",
        "#     heatmap.tick_params(axis='x', pad=1, length=2)\n",
        "#     heatmap.tick_params(axis='y', pad=.5, length=2)\n",
        "#     heatmap.yaxis.labelpad = 3\n",
        "#     heatmap.invert_yaxis()\n",
        "#     heatmap.set_facecolor('#E7E6E6')\n",
        "#     # split axes of heatmap to put colorbar\n",
        "#     ax_divider = make_axes_locatable(ax1)\n",
        "#     cax = ax_divider.append_axes('left', size='7%', pad='33%')\n",
        "#     # # make colorbar for heatmap.\n",
        "#     # # Heatmap returns an axes obj but you need to get a mappable obj (get_children)\n",
        "#     cbar = colorbar(ax1.get_children()[0], cax=cax, orientation='vertical', format='%.0f%%')\n",
        "#     cax.yaxis.set_ticks_position('left')\n",
        "#     cbar.solids.set_edgecolor(\"face\")\n",
        "#     cbar.ax.tick_params(labelsize=11, length=4, pad=2)\n",
        "#     ax1.set_title('% Attention', size=12)\n",
        "#     ax1.set_xlabel('Head', size=11)\n",
        "#     ax1.set_ylabel('Layer', size=11)\n",
        "#     for _, spine in ax1.spines.items():\n",
        "#         spine.set_visible(True)\n",
        "#     ax2.set_title('Max', size=12)\n",
        "#     bp = sns.barplot(x=layer_max * 100, ax=ax2, y=list(range(layer_max.shape[0])), color=\"#5a3dc4\", orient=\"h\",\n",
        "#                      edgecolor=\"none\")\n",
        "#     formatter = FuncFormatter(lambda y, pos: '0' if (y == 0) else \"%d%%\" % (y))\n",
        "#     ax2.xaxis.set_major_formatter(formatter)\n",
        "#     plt.setp(bp.get_xticklabels(), fontsize=11)\n",
        "#     bp.tick_params(axis='x', pad=1, length=3)\n",
        "#     ax2.invert_yaxis()\n",
        "#     ax2.set_yticklabels([])\n",
        "#     ax2.spines['top'].set_visible(False)\n",
        "#     ax2.spines['right'].set_visible(False)\n",
        "#     ax2.spines['left'].set_visible(False)\n",
        "#     ax2.xaxis.set_ticks_position('bottom')\n",
        "#     ax2.axvline(0, linewidth=.85, color='black')\n",
        "\n",
        "#     # plt.tight_layout()\n",
        "#     plt.show()\n",
        "#     fig_path = Path(dir_path) / f'{filename}.jpg'\n",
        "#     fig.savefig(fig_path, bbox_inches='tight', pad_inches=0)\n",
        "#     plt.close()\n",
        "\n",
        "\n",
        "# def top_heads_attention_proportions(attentions_all_layers, proportion=\"attention\", theta=0, min_total=0):\n",
        "#     max_attentive_heads_pvalues = []\n",
        "#     inv_class_labels_dict = {v:k for k, v in config_dict['CLASS_LABELS'].items()}\n",
        "#     if theta == None:\n",
        "#         raise ValueError(\"top_heads_attention_proportions: theta: got None, expected float\")\n",
        "\n",
        "#     top_heads_attention_pct = {}\n",
        "\n",
        "#     for target_label in attentions_all_layers.keys():\n",
        "#         attentions_sum = attentions_all_layers[target_label]\n",
        "#         if inv_class_labels_dict[target_label] not in top_heads_attention_pct.keys():\n",
        "#             top_heads_attention_pct[inv_class_labels_dict[target_label]] = {}\n",
        "#         for domain in domain_coordinates_1based.keys():\n",
        "#             domain_start_idx, domain_end_idx = convert_domain_coords_in_token_indices(domain)\n",
        "\n",
        "#             # (1) the proportion of high-confidence attention arcs (αi,j > θ) for which f(i,j)=1 for top head\n",
        "#             weight_domain_proportion_by_head, num_pos, num_total = calculate_weight_domain_proportion_by_head(attentions_sum, domain, proportion='high-attention-tokens-count', theta=theta)\n",
        "#             exclude_mask = np.array(num_total) < min_total\n",
        "#             masked_weight_domain_proportion_by_head = np.ma.masked_array(weight_domain_proportion_by_head, mask=exclude_mask)\n",
        "#             top_head = np.unravel_index(np.argmax(masked_weight_domain_proportion_by_head, axis=None), masked_weight_domain_proportion_by_head.shape)\n",
        "#             high_confidence_pct = masked_weight_domain_proportion_by_head[top_head[0],top_head[1]].item() * 100\n",
        "#             num_pos = num_pos[top_head[0],top_head[1]].item()\n",
        "#             num_total = num_total[top_head[0],top_head[1]].item()\n",
        "\n",
        "#             # # (2) background: the proportion of all possible pairs i, j for which f(i,j)=1\n",
        "#             if proportion == \"attention\" or proportion == \"high-confidence-attention\":\n",
        "#                 weight_domain_count_by_head = attentions_sum[:, :, :, domain_start_idx:domain_end_idx+1].sum((2, 3))\n",
        "#                 weight_total_count_by_head = attentions_sum.sum((2, 3))\n",
        "#                 num_pos_background = weight_domain_count_by_head[top_head[0],top_head[1]].item()\n",
        "#                 num_total_background = weight_total_count_by_head[top_head[0],top_head[1]].item()\n",
        "#                 background_pct = num_pos_background / num_total_background * 100\n",
        "#             elif proportion == \"high-attention-tokens-count\":\n",
        "#                 mask_domain = torch.zeros(attentions_sum.shape, dtype=torch.bool)\n",
        "#                 mask_domain[:, :, :, domain_start_idx:domain_end_idx+1] = 1\n",
        "#                 weight_domain_count_by_head = mask_domain.long().sum((2, 3))\n",
        "#                 mask_total = torch.ones(attentions_sum.shape, dtype=torch.bool)\n",
        "#                 weight_total_count_by_head = mask_total.long().sum((2, 3))\n",
        "#             else:\n",
        "#                 raise ValueError(\"plt_attentions_domain: proportion must be one of %r.\" % [\"attention\", \"high-attention-tokens\"])\n",
        "\n",
        "#             # p-value for statistical significance\n",
        "#             stat, p_value = proportions_ztest(np.asarray([num_pos_background, num_pos]), np.asarray([num_total_background, num_total]))\n",
        "#             m = masked_weight_domain_proportion_by_head.shape[0]*masked_weight_domain_proportion_by_head.shape[1]\n",
        "#             alpha = 0.05 / m    # Bonferroni adjustment\n",
        "#             statistical_significance = p_value < alpha\n",
        "#             max_attentive_heads_pvalues.append([inv_class_labels_dict[target_label], domain, f'{top_head[0]+1}-{top_head[1]+1}', high_confidence_pct, background_pct, f'{p_value:.25f}', statistical_significance])\n",
        "    \n",
        "#             top_heads_attention_pct[inv_class_labels_dict[target_label]][domain] = high_confidence_pct\n",
        "\n",
        "#     df_top_heads_attention_pct = pd.DataFrame(top_heads_attention_pct)\n",
        "#     df_top_heads_attention_pct['MEDIAN'] = df_top_heads_attention_pct.median(axis=1)\n",
        "#     df_max_attentive_heads_pvalues = pd.DataFrame(max_attentive_heads_pvalues, columns=['Class', 'Domain', 'Top head', 'Attn %', 'Background %', 'p-value', f'p<{alpha:.8f}'])\n",
        "\n",
        "#     return df_top_heads_attention_pct.sort_values(\"MEDIAN\", axis=0, ascending=False), df_max_attentive_heads_pvalues\n",
        "\n",
        "# def show_attentions_for_each_domain(attentions_all_layers, dir_path, proportion=\"attention\"):\n",
        "#     inv_class_labels_dict = {v:k for k, v in config_dict['CLASS_LABELS'].items()}\n",
        "#     if proportion == 'high-attention-tokens-count':\n",
        "#         theta = 0.3\n",
        "#     else:\n",
        "#         theta = None\n",
        "\n",
        "#     for target_label in attentions_all_layers.keys():\n",
        "#         for domain in domain_coordinates_1based.keys():\n",
        "#             plt_attentions_domain(attentions_all_layers[target_label], \n",
        "#                             domain, \n",
        "#                             dir_path, \n",
        "#                             filename=f\"{domain}_{inv_class_labels_dict[int(target_label)]}\", \n",
        "#                             proportion=proportion,\n",
        "#                             theta=theta,\n",
        "#                             title=f\"Domain: {domain}, Class: {inv_class_labels_dict[int(target_label)]}\")\n",
        "\n",
        "\n",
        "def plt_attentions(mat, tick_labels, dir_path, filename=\"attention_matrix\", theta=0, fig_size=(130,100), annot=False, cmap=sns.color_palette(\"viridis_r\"), title=None):\n",
        "    '''\n",
        "    plot the NxN matrix passed as a heat map\n",
        "\n",
        "    mat: square matrix to visualize\n",
        "    tick_labels: labels for xticks and yticks (the tokens in our case)\n",
        "    '''\n",
        "\n",
        "    if not os.path.exists(dir_path):\n",
        "        os.makedirs(dir_path)\n",
        "        print(f\"Directory '{dir_path}' created\")\n",
        "\n",
        "    #percentile_threshold = np.percentile(mat, percentile)\n",
        "    # mask_att_below_thresh = mat < mat.max() * threshold_ratio\n",
        "    # mask_att_above_thresh = mat >= mat.max() * threshold_ratio\n",
        "    mask_att_below_thresh = mat < theta\n",
        "    mask_att_above_thresh = mat >= theta\n",
        "    \n",
        "    xs, ys = np.where(mask_att_above_thresh == True) \n",
        "    high_attention_positions = []\n",
        "    print(len(xs))\n",
        "    print(len(ys))\n",
        "    print(mat.shape)\n",
        "    for x,y in zip(xs,ys):\n",
        "        high_attention_positions.append([tick_labels[x],tick_labels[y],mat[x,y]])\n",
        "    sorted_high_attention_positions = pd.DataFrame(high_attention_positions, columns=['Row','Col','Attn. Score']).sort_values(by=['Attn. Score'], ascending=False)\n",
        "    with open(f\"{Path(dir_path) / filename}.txt\", 'a') as fp:\n",
        "        fp.write(title+'\\n')\n",
        "        fp.write(sorted_high_attention_positions.to_string(index=False)) \n",
        "        fp.write('\\n')\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=fig_size) \n",
        "    ax = sns.heatmap(mat, \n",
        "                     annot=annot,\n",
        "                     yticklabels=tick_labels,\n",
        "                     xticklabels=tick_labels, \n",
        "                     cmap=cmap,\n",
        "                     mask=mask_att_below_thresh)   \n",
        "    ax.xaxis.set_ticks_position('top')\n",
        "    ax.set_xticklabels(ax.get_xticklabels(), rotation=90, fontsize=8)\n",
        "    ax.set_yticklabels(ax.get_yticklabels(), fontsize=8)\n",
        "    xtick_above_threshold = [np.any(mask_att_above_thresh[:,i]) for i in range(0, len(mask_att_above_thresh))]\n",
        "    ytick_above_threshold = [np.any(mask_att_above_thresh[i,:]) for i in range(0, len(mask_att_above_thresh))]\n",
        "    for (is_above_threshold, ticklbl) in zip(xtick_above_threshold, ax.xaxis.get_ticklabels()):\n",
        "        if is_above_threshold:\n",
        "            # ticklbl.set_weight(\"bold\")\n",
        "            ticklbl.set(color = 'black', backgroundcolor='yellow', weight='bold', alpha=0.5)\n",
        "        # ticklbl.set_color('blue' if is_above_threshold else 'black')\n",
        "        # ticklbl.set_backgroundcolor('blue' if is_above_threshold else '0')\n",
        "        # ticklbl.set(color = 'white' if is_above_threshold else 'black', backgroundcolor='blue' if is_above_threshold else 'white')\n",
        "    for (is_above_threshold, ticklbl) in zip(ytick_above_threshold, ax.yaxis.get_ticklabels()):\n",
        "        if is_above_threshold:\n",
        "            ticklbl.set(color = 'black', backgroundcolor='yellow', weight='bold', alpha=0.5)\n",
        "            # ticklbl.set_weight(\"bold\")\n",
        "    if title:\n",
        "        ax.set_title(title, fontsize=80)\n",
        "    else:\n",
        "        ax.set_title('Attention matrix', fontsize=80)\n",
        "    cbar = ax.collections[0].colorbar\n",
        "    cbar.ax.tick_params(labelsize=80)\n",
        "\n",
        "    # # padding_idx = n_tokens_per_seq + 2   # +2 to consider also 'CLS' and 'SEP' tokens\n",
        "    # padding_idx = tick_labels.index(next(i for i in tick_labels if i.endswith('_[PAD]')))\n",
        "    # ax.hlines([padding_idx], *ax.get_xlim(), linestyles='dashed')\n",
        "    # ax.vlines([padding_idx], *ax.get_ylim(), linestyles='dashed')\n",
        "\n",
        "    # plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # n_figures = len(os.listdir(dir_path))\n",
        "    # if n_figures > 0:\n",
        "    #     fig_path = Path(dir_path) / f'{filename}({n_figures}).jpg'\n",
        "    # else:\n",
        "    fig_path = Path(dir_path) / f'{filename}.jpg'\n",
        "    fig.savefig(fig_path, bbox_inches='tight', pad_inches=0)\n",
        "\n",
        "\n",
        "def plot_overlaid_attentions(dict_attentions, tick_labels, dir_path, threshold_ratio=0.5, fig_size=(80,80), annot=False, title=None, cmap=colormaps):\n",
        "    '''\n",
        "    Plot heatmap with all attention matrices of last layer of different classes\n",
        "    superimposed with different colours \n",
        "\n",
        "    dict_attentions: square matrices to visualize\n",
        "    path = path to save\n",
        "    tick_labels: labels for xticks and yticks (the tokens in our case)\n",
        "    '''\n",
        "    fig, ax = plt.subplots(figsize=fig_size) \n",
        "    i = 0\n",
        "    for label, mat in dict_attentions.items():\n",
        "        #ax = sns.heatmap(mat, annot=annot, cmap=cmap[label])\n",
        "        mask_att_below_thresh = mat < mat.max() * threshold_ratio\n",
        "        ax = sns.heatmap(mat, \n",
        "                         annot=annot, \n",
        "                         mask=mask_att_below_thresh, \n",
        "                         cmap=cmap[int(label)], \n",
        "                         alpha=1-i/len(dict_attentions.keys()), #alpha=0.9, \n",
        "                         xticklabels=1, yticklabels=1,\n",
        "                         square = True, \n",
        "                         cbar = False,\n",
        "                        #  cbar_kws={\"shrink\":0.10, \"label\": f\"{int(label)}\"}\n",
        "                         )\n",
        "        i += 1\n",
        "\n",
        "    ax.xaxis.set_ticks_position('top')\n",
        "    ax.set_xticklabels(tick_labels, rotation=90)\n",
        "    ax.set_yticklabels(tick_labels, rotation=0)\n",
        "    # ax.xaxis.set_ticks_position('top')\n",
        "    # ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
        "    # mask_att_above_thresh = mat > mat.max() / 2\n",
        "\n",
        "    # padding_idx = n_tokens_per_seq + 2   # +2 to consider also 'CLS' and 'SEP' tokens\n",
        "    padding_idx = next(i for i in tick_labels if i.endswith('[PAD]'))\n",
        "    ax.hlines([padding_idx], *ax.get_xlim(), linestyles='dashed')\n",
        "    ax.vlines([padding_idx], *ax.get_ylim(), linestyles='dashed')\n",
        "\n",
        "    if title:\n",
        "        ax.set_title(title, fontsize=80)\n",
        "    else:\n",
        "        ax.set_title('Attention matrix', fontsize=80)\n",
        "\n",
        "    # plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    if not os.path.exists(dir_path):\n",
        "        os.makedirs(dir_path)\n",
        "        print(f\"Directory '{dir_path}' created\")\n",
        "\n",
        "    fig_path = Path(dir_path) / f'{title}.jpg'\n",
        "    fig.savefig(fig_path, bbox_inches='tight', pad_inches=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MUv_tTHm1ky"
      },
      "source": [
        "####Test functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dKbXNLltak08"
      },
      "outputs": [],
      "source": [
        "def distance_cone(mat):\n",
        "    # norm_per_row = np.linalg.norm(mat, axis=1)\n",
        "    normalized_rows_mat =  mat/np.linalg.norm(mat, ord=2, axis=1, keepdims=True)\n",
        "    # norm_per_row = np.linalg.norm(norm, ord=2, axis=1, keepdims=True) #math.sqrt(sum([i**2 for i in mat[0]]))\n",
        "    # print(f'NORMA RIGhe = {norm_per_row}')\n",
        "    # norm = [i/norm_per_row for i in mat[0]]\n",
        "    # print(norm)\n",
        "\n",
        "    # #print(root_sum_lambda_i)\n",
        "    # norm_lambda = [abs(lambda_i)/root_sum_lambda_i for lambda_i in eigvals]\n",
        "    # # print(norm_per_row)\n",
        "    # normalized_rows_mat = []\n",
        "    # for row in range(mat.shape[0]):\n",
        "    #     normalized_rows_mat.append(mat[row, :] / norm_per_row[row])\n",
        "    summed_rows_array = np.sum(normalized_rows_mat, axis=0)\n",
        "    norm_summed_rows_mat = np.linalg.norm(summed_rows_array)\n",
        "    return norm_summed_rows_mat\n",
        "\n",
        "def singular_values(mat):\n",
        "    return abs(np.linalg.svd(mat, compute_uv=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F16BM5fz0E_K"
      },
      "outputs": [],
      "source": [
        "def mat_save_csv(mat, name, dirpath):\n",
        "    if not os.path.exists(dirpath):\n",
        "        os.makedirs(dirpath)\n",
        "        print(f\"Directory '{dirpath}' created\")\n",
        "    np.savetxt(Path(dirpath) / f'{name}.csv', mat, delimiter=\",\")\n",
        "\n",
        "def chi2_test(multihead_output):\n",
        "    pass\n",
        "    #n_bins = 28\n",
        "    # for row in range(multihead_output.shape[0]):\n",
        "    #     # print(f'min={min(multihead_output[row,:])} | max={max(multihead_output[row,:])}')\n",
        "    #     # print(multihead_output[row,:])\n",
        "    #     bins = pd.cut(multihead_output[row,:], bins=n_bins)\n",
        "    #     bin_counts = pd.value_counts(bins)\n",
        "    #     print(bins.index.tolist())\n",
        "\n",
        "    #     mean_val = []\n",
        "    #     sum_bins = 0\n",
        "    #     for i,bin_count in enumerate(bin_counts):\n",
        "    #         bin_interval = bin_counts.index.tolist()[i]\n",
        "    #         mv = (bin_interval.right-bin_interval.left)/2\n",
        "    #         mean_val.append(mv)\n",
        "    #         n = bin_count*mv\n",
        "    #         sum_bins += n\n",
        "    #     empirical_mean = sum_bins / 768\n",
        "    #     mean_row = np.mean(multihead_output[row,:])\n",
        "        \n",
        "    #     sum_quadr_res = 0\n",
        "    #     for i,bin_count in enumerate(bin_counts):\n",
        "    #         mv = mean_val[i]\n",
        "    #         sum_quadr_res += ((mv - empirical_mean)**2) * bin_count \n",
        "    #     empirical_stddev = math.sqrt(1/(768) * sum_quadr_res)\n",
        "    #     stddev_row = np.std(multihead_output[row,:])\n",
        "        \n",
        "    #     exp_freq = []\n",
        "    #     for i,bin_count in enumerate(bin_counts):\n",
        "    #         exp_freq.append(1/(math.sqrt(2*math.pi) * empirical_stddev) * math.exp(-(mean_val[i]-empirical_mean)**2/(2*empirical_stddev**2)))\n",
        "        \n",
        "    #     chisq_test_stat, p_value = chisquare(bin_counts/768, exp_freq, n_bins-1)\n",
        "    #     print(f'row {row} | chisq_test_stat ={chisq_test_stat} | p-value = {p_value}')\n",
        "\n",
        "    #     # print(f'empirical_mean = {empirical_mean} | empirical_stddev = {empirical_stddev}')\n",
        "    #     print(f'mean = {mean_row} | stddev = {stddev_row}')\n",
        "    #     print(mean_val)\n",
        "    #     plt.bar(mean_val, bin_counts/768, width=0.2)\n",
        "    #     # plt.hist(multihead_output[row,:]/768, bins=n_bins)\n",
        "    #     mu = mean_row\n",
        "    #     variance = stddev_row**2\n",
        "    #     sigma = stddev_row\n",
        "    #     x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n",
        "    #     # plt.plot(x, stats.norm.pdf(x, mu, sigma))\n",
        "    #     # mu = mean_row\n",
        "    #     # variance = stddev_row**2\n",
        "    #     # sigma = stddev_row\n",
        "    #     # x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n",
        "    #     def f(y):\n",
        "    #         return [1/(math.sqrt(2*math.pi) * stddev_row) * math.exp(-(yi-mean_row)**2/(2*stddev_row**2)) for yi in y]\n",
        "    #     plt.plot(x, f(x), color='black')\n",
        "    #     plt.show()\n",
        "\n",
        "    #     break    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KWdpqY7Blnyv"
      },
      "outputs": [],
      "source": [
        "def compute_Von_Neumann_entropy_eigvals(mat, head_lay):\n",
        "    eigvals = np.linalg.eigvals(mat)\n",
        "\n",
        "    # print(f'{head_lay} {len(eigvals) - np.count_nonzero(eigvals)}/{len(eigvals)}')\n",
        "    # print(f'{head_lay} {eigvals}')\n",
        "\n",
        "    # dir_path = math_interpret_dir\n",
        "    # fig = plt.figure(figsize=(8,8))\n",
        "    # plt.hist(eigvals)\n",
        "    # plt.title(f\"Histogram of eigenvalues of the attention matrix for {head_lay}\")\n",
        "    # plt.grid(linestyle = '--')\n",
        "    # plt.yticks(list(plt.yticks()[0]) + [1])\n",
        "    # plt.show()\n",
        "    # dit_path_head = Path(dir_path) / 'hist_sing_val' / head_lay\n",
        "    # if not os.path.exists(dit_path_head):\n",
        "    #     os.makedirs(dit_path_head)\n",
        "    # fig_path = Path(dit_path_head) / f'head_lay.jpg'\n",
        "    # fig.savefig(fig_path, bbox_inches='tight')\n",
        "    # plt.close()\n",
        "\n",
        "    root_sum_lambda_i = math.sqrt(sum([abs(lambda_i)**2 for lambda_i in eigvals]))\n",
        "    #print(root_sum_lambda_i)\n",
        "    norm_lambda = [abs(lambda_i)/root_sum_lambda_i for lambda_i in eigvals]\n",
        "    #print(norm_lambda)\n",
        "    return -sum([abs(lambda_i_norm) * np.log(abs(lambda_i_norm)) for lambda_i_norm in norm_lambda if lambda_i_norm!=float(0)])\n",
        "\n",
        "    # root_sum_lambda_i = math.sqrt(sum([abs(lambda_i)**2 for lambda_i in eigvals]))\n",
        "    # #print(root_sum_lambda_i)\n",
        "    # norm_lambda = [lambda_i/root_sum_lambda_i for lambda_i in eigvals]\n",
        "    # #print(norm_lambda)\n",
        "    # return -sum([lambda_i_norm * np.log(lambda_i_norm) for lambda_i_norm in norm_lambda if lambda_i_norm!=float(0)])\n",
        "\n",
        "def compute_Shannon_entropy(mat, head_lay):\n",
        "    \n",
        "    bins = pd.cut(mat.ravel(), bins=20)\n",
        "    shannon_entropy=0\n",
        "    tot_count = len(mat.ravel())\n",
        "    pjs = pd.value_counts(bins) / tot_count\n",
        "    for pj in pjs:\n",
        "        if pj != 0:\n",
        "            shannon_entropy += pj*np.log(pj)\n",
        "\n",
        "    return -shannon_entropy\n",
        "\n",
        "def supervisedBertClassifierTest(input_embs, model, log_fp_test, theta=0, selected_layer_head_list=None, dir_path=None, title=\"\"):\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    print('Calculating predictions...')\n",
        "    log_fp_test.write(\"\\nTest:\\n\")\n",
        "    log_fp_test.write(\"=====\\n\")\n",
        "    # Put model in evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    final_data_test = {'outputs' : [],\n",
        "                  'logits' : [],\n",
        "                  'output_embeddings' : [],\n",
        "                  'input_embeddings' : [],\n",
        "                  }\n",
        "    attentions = {}\n",
        "    attentions_last_layer = None # 1 heatmap per class, with attention scores of last layer of all samples \n",
        "    attentions_all_layers = None # 1 list of attention matrices per class, with attention scores of all layers of 1 sample\n",
        "    attentions_all_layers_thresh = None\n",
        "    repr_token_base_positions_axis = None\n",
        "\n",
        "    distance_cones={}\n",
        "    distance_cones_1_sample={}\n",
        "    count_layer = {k:0 for k in range(-1, n_layers)}\n",
        "\n",
        "    layer_query_weight_names = [f'bert.encoder.layer.{l}.attention.self.query.weight' for l in range(n_layers)]\n",
        "    layer_key_weight_names = [f'bert.encoder.layer.{l}.attention.self.key.weight' for l in range(n_layers)]\n",
        "    layer_value_weight_names = [f'bert.encoder.layer.{l}.attention.self.value.weight' for l in range(n_layers)]\n",
        "    model_params = dict(model.named_parameters())\n",
        "\n",
        "    # Predict \n",
        "\n",
        "    # Unpack the inputs from our dataloader\n",
        "    input_embs = input_embs.to(device, dtype = torch.long)\n",
        "\n",
        "    # Telling the model not to compute or store gradients, saving memory and \n",
        "    # speeding up prediction\n",
        "    with torch.no_grad():\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        outputs = model(inputs_embeds=input_embs,\n",
        "                    return_dict=True,\n",
        "                    output_attentions=True,\n",
        "                    output_hidden_states=True)        \n",
        "\n",
        "    logits = outputs.logits\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "\n",
        "    if config_dict['TASK_TYPE'] !='clustering':\n",
        "        final_data_test['logits'].extend(outputs.logits.cpu().detach().numpy().tolist())\n",
        "        # final_data_test['outputs'].extend(torch.softmax(outputs.logits).cpu().detach().numpy().tolist())\n",
        "        if config_dict['N_CLASSES'] > 2:\n",
        "            final_data_test['outputs'].extend(torch.softmax(outputs.logits, dim=1).cpu().detach().numpy().tolist())\n",
        "        else:\n",
        "            final_data_test['outputs'].extend(torch.sigmoid(outputs.logits).cpu().detach().numpy().tolist())\n",
        "\n",
        "    #############################################   \n",
        "    sample_idx = 0\n",
        "\n",
        "    if config_dict['TASK_TYPE']=='print_layer_output':\n",
        "        input_embs = outputs.hidden_states[0][sample_idx].cpu().detach().numpy() # X = imput to current layer (output of previous layer)\n",
        "                                                                                                # NB: hidden_states of attn layers shifted by +1 because hidden_states[0] is embedding layer\n",
        "        mat_save_csv(input_embs, f'input_embeddings', math_interpret_dir)\n",
        "        return final_data_test, attentions      \n",
        "\n",
        "    # get attention matrices\n",
        "    # NB:   outputs.attentions is a tuple containing 12 elements, i.e. attentions of the 12 layers of Bert \n",
        "    #       eg. if we consider first layer from the bottom (closest to the input):\n",
        "    #           print(outputs.attentions[0].shape) \n",
        "    #               -> torch.Size([4, 12, 512, 512]) -> [batch_size , num_heads, seq_len, seq_len]\n",
        "    elif config_dict['TASK_TYPE']=='attention_analysis' or config_dict['TASK_TYPE']=='attention_flow':\n",
        "\n",
        "        # get attention scores of sample from all heads in all layers\n",
        "        sample_attentions = []\n",
        "        sample_attentions_thresh = []\n",
        "        for layer in range(n_layers):\n",
        "            layer_attentions = []\n",
        "            masked_layer_attentions = []\n",
        "            for head in range(n_heads):\n",
        "                # Source: \"Bertology meets Biology...\": We exclude attention to the [SEP] delimiter token, as it has been shown to \n",
        "                # be a “no-op” attention token (Clark et al., 2019), as well as attention to \n",
        "                # the [CLS] token, which is not explicitly used in language modeling.\n",
        "                # Additionally, exclude attention on [PAD] tokens.\n",
        "                head_attentions = get_attentions(outputs.attentions, sample_idx_in_batch=sample_idx, layer=layer, attention_head=head, sum=False)\n",
        "                layer_attentions.append(head_attentions)\n",
        "                mask_att_below_thresh = head_attentions < theta\n",
        "                masked_head_attentions = np.ma.masked_array(head_attentions, mask=mask_att_below_thresh, fill_value=0)\n",
        "                masked_layer_attentions.append(masked_head_attentions.filled())\n",
        "            sample_attentions.append(layer_attentions)\n",
        "            sample_attentions_thresh.append(masked_layer_attentions)\n",
        "        \n",
        "        # update sum of class attention scores of all heads of all layers\n",
        "        attentions_all_layers = torch.zeros(np.asarray(sample_attentions).shape, dtype=torch.double)\n",
        "        repr_token_base_positions_axis = []\n",
        "        for n in range(config_dict['MAX_LENGTH']):\n",
        "            if n==0:\n",
        "                repr_token_base_positions_axis.append('[CLS]')\n",
        "            else:\n",
        "                repr_token_base_positions_axis.append(f\"{n+1}\") \n",
        "        # repr_token_base_positions_axis [target_label] = [f\"{n*config_dict['STRIDE']-config_dict['STRIDE']}_{tokenizer.convert_ids_to_tokens(id)}\" for n,id in enumerate(ids[sample_idx].cpu().detach().numpy().tolist())]\n",
        "        \n",
        "        attentions_all_layers_thresh = torch.zeros(np.asarray(sample_attentions_thresh).shape, dtype=torch.double)\n",
        "        \n",
        "        for layer in range(n_layers):\n",
        "            for head in range(n_heads):\n",
        "                attentions_all_layers[layer][head] = attentions_all_layers[layer][head] + np.asarray(sample_attentions[layer][head])\n",
        "                attentions_all_layers_thresh[layer][head] = attentions_all_layers_thresh[layer][head] + np.asarray(sample_attentions_thresh[layer][head])\n",
        "\n",
        "    # elif config_dict['TASK_TYPE']=='check_normality':\n",
        "    #     for sample_idx in range(0,len(seq_ids)):\n",
        "    #         target_label = label_ids[sample_idx]\n",
        "    #         name_seq=seq_ids[sample_idx]\n",
        "    #         if target_label == np.argmax(logits[sample_idx]): # correct prediction\n",
        "    #             X = outputs.hidden_states[0][sample_idx].cpu().detach().numpy()  # X = imput to current layer (output of previous layer)\n",
        "    #                                                                                     # NB: hidden_states of attn layers shifted by +1 because hidden_states[0] is embedding layer\n",
        "    #                                                                                     # token embeddings shape=(n_tokens_in_seq, emb_dim)=(512, 768)\n",
        "\n",
        "    #             for i, row in enumerate(X):\n",
        "    #                 print(f'Mean row {i}: {np.mean(row)}')  \n",
        "    #         break\n",
        "                \n",
        "    \n",
        "    elif config_dict['TASK_TYPE']=='distance_cones_analysis':\n",
        "        for layer in set(np.asarray(selected_layer_head_list)[:,0]):\n",
        "            X = outputs.hidden_states[layer][sample_idx].cpu().detach().numpy()  # X = imput to current layer (output of previous layer)\n",
        "                                                                                # NB: hidden_states of attn layers shifted by +1 because hidden_states[0] is embedding layer\n",
        "                                                                                # token embeddings shape=(n_tokens_in_seq, emb_dim)=(512, 768)\n",
        "            # print(f'-------NORMA X[0]: {np.linalg.norm(X[0])}')\n",
        "            rows_sum_X = np.sum(X, axis=0)\n",
        "            # norm = np.linalg.norm(rows_sum_X, ord=2)\n",
        "            # print(f'-------NORMA X: {norm}')\n",
        "            # model_params = dict(model.named_parameters())\n",
        "            # print(model_params[\"bert.encoder.layer.0.attention.self.value.weight\"].data)\n",
        "            W_v = model_params[f\"bert.encoder.layer.{layer}.attention.self.value.weight\"].data.cpu().detach().numpy()\n",
        "            W_q = model_params[f\"bert.encoder.layer.{layer}.attention.self.query.weight\"].data.cpu().detach().numpy()\n",
        "            W_k = model_params[f\"bert.encoder.layer.{layer}.attention.self.key.weight\"].data.cpu().detach().numpy()\n",
        "            emb_dim = X.shape[1]\n",
        "            d_k = int(emb_dim / n_heads)\n",
        "            multihead_output = None\n",
        "\n",
        "            for head in np.sort([h for l, h in selected_layer_head_list if l==layer]):\n",
        "                W_v_i = W_v[:, head*d_k : head*d_k + d_k]\n",
        "                W_q_i = W_q[:, head*d_k : head*d_k + d_k]\n",
        "                W_k_i = W_k[:, head*d_k : head*d_k + d_k]\n",
        "                V_i = np.matmul(X, W_v_i)\n",
        "                Q_i = np.matmul(X, W_q_i)\n",
        "                K_i = np.matmul(X, W_k_i)\n",
        "\n",
        "                softmax_i = torch.softmax(torch.tensor(np.matmul(Q_i, K_i.T) / math.sqrt(d_k)), dim=1).cpu().detach().numpy()\n",
        "                output_head_i = np.matmul(softmax_i, V_i)\n",
        "\n",
        "                if head == 5-1:\n",
        "                    output_head_5 = np.copy(output_head_i)\n",
        "\n",
        "                if multihead_output is None:\n",
        "                    multihead_output = np.copy(output_head_i)\n",
        "                else:\n",
        "                    multihead_output = np.hstack((multihead_output, output_head_i))\n",
        "\n",
        "            layerNorm = nn.LayerNorm(model.config.hidden_size, eps=model.config.layer_norm_eps)\n",
        "            multihead_output = layerNorm(torch.from_numpy(X + multihead_output)).cpu().detach().numpy()\n",
        "\n",
        "            layer_output = outputs.hidden_states[layer+1][sample_idx].cpu().detach().numpy() # output of current layer\n",
        "\n",
        "        #     print(f'Saving mat L{layer+1}')\n",
        "        #     dirpath = Path(math_interpret_dir) / 'Y_outputs'\n",
        "        #     mat_save_csv(multihead_output, f'Y_output_L{layer+1}', dirpath)\n",
        "\n",
        "        # return final_data_test, test_accuracies, attentions, timings\n",
        "            \n",
        "            if layer not in distance_cones:\n",
        "                distance_cones[layer] = {}\n",
        "\n",
        "            dc_X = distance_cone(X)\n",
        "            # print(f'-------({name_seq}) DISTANCE CONE X: {dc_X}')\n",
        "            if 'Layer input' not in distance_cones[layer]:\n",
        "                distance_cones[layer]['Layer input'] = []\n",
        "            distance_cones[layer]['Layer input'].append(dc_X)\n",
        "\n",
        "            dc_output_head_5 = distance_cone(output_head_5)\n",
        "            # print(f'-------({name_seq}) DISTANCE CONE output_head_5: {dc_output_head_5}')\n",
        "            if 'Head output' not in distance_cones[layer]:\n",
        "                distance_cones[layer]['Head output'] = []\n",
        "            distance_cones[layer]['Head output'].append(dc_output_head_5)\n",
        "\n",
        "            dc_multihead_output = distance_cone(multihead_output)\n",
        "            # print(f'-------({name_seq}) DISTANCE CONE multihead_i: {dc_multihead_output}')\n",
        "            if 'Multihead output' not in distance_cones[layer]:\n",
        "                distance_cones[layer]['Multihead output'] = []\n",
        "            distance_cones[layer]['Multihead output'].append(dc_multihead_output)\n",
        "\n",
        "            dc_layer_output = distance_cone(layer_output)\n",
        "            # print(f'-------({name_seq}) DISTANCE CONE layer_output: {layer_output}')\n",
        "            if 'Layer output' not in distance_cones[layer]:\n",
        "                distance_cones[layer]['Layer output'] = []\n",
        "            distance_cones[layer]['Layer output'].append(dc_layer_output)\n",
        "\n",
        "            if count_layer[layer] == 0:\n",
        "                if layer == 0:\n",
        "                    distance_cones_1_sample[-1] = dc_X\n",
        "                distance_cones_1_sample[layer] = dc_layer_output\n",
        "           \n",
        "                            \n",
        "\n",
        "    # elif config_dict['TASK_TYPE']=='layer_output_analysis':     \n",
        "    #     output_layers_dir = Path(math_interpret_dir) / \"output_layer_histograms\"\n",
        "    #     if not os.path.exists(output_layers_dir):\n",
        "    #         os.makedirs(output_layers_dir)\n",
        "    #         print(f\"Directory '{output_layers_dir}' created\")\n",
        "\n",
        "    #     for sample_idx in range(0,len(seq_ids)):\n",
        "    #         target_label = label_ids[sample_idx]\n",
        "    #         name_seq=seq_ids[sample_idx]\n",
        "            \n",
        "    #         if target_label == config_dict['CLASS_LABELS']['omicron'] and target_label == np.argmax(logits[sample_idx]): # correct prediction\n",
        "\n",
        "    #             # output layer histogram:\n",
        "    #             for layer in set(np.asarray(selected_layer_head_list)[:,0]):\n",
        "    #                 layer_output = outputs.hidden_states[layer+1][sample_idx].cpu().detach().numpy()\n",
        "    #                 layer_ouput_sum_rows = np.sum(layer_output, axis=0)\n",
        "    #                 fig = plt.figure(figsize=(8,8))\n",
        "    #                 plt.hist(layer_ouput_sum_rows, bins=27)\n",
        "    #                 plt.title(f\"L{layer+1} output\")\n",
        "    #                 plt.grid(linestyle = '--')\n",
        "    #                 plt.yticks(list(plt.yticks()[0]) + [1])\n",
        "    #                 plt.show()\n",
        "    #                 fig_path = Path(output_layers_dir) / f'output_layer_{layer+1}.jpg'\n",
        "    #                 fig.savefig(fig_path)\n",
        "    #         return final_data_test, test_accuracies, attentions, timings\n",
        "\n",
        "\n",
        "    elif config_dict['TASK_TYPE']=='singularvalues_ratio_analysis':\n",
        "        mat_ratio_max_min_sv_softmax_i = np.zeros((n_layers,n_heads))\n",
        "        mat_ratio_2ndmin_min_sv_softmax_i = np.zeros((n_layers,n_heads))\n",
        "        mat_ratio_max_min_sv_W_v_i = np.zeros((n_layers,n_heads))\n",
        "        mat_ratio_2ndmin_min_sv_W_v_i = np.zeros((n_layers,n_heads))\n",
        "        mat_count_zero_sv_softmax_i = np.zeros((n_layers,n_heads))\n",
        "        mat_count_zero_sv_W_v_i = np.zeros((n_layers,n_heads))\n",
        "        histograms = {}\n",
        "\n",
        "        dir_path_sv = Path(math_interpret_dir) / f'sing_vals_{title}'\n",
        "        if not os.path.exists(dir_path_sv):\n",
        "            os.makedirs(dir_path_sv)\n",
        "        singvals_ratio_file = Path(dir_path_sv) / \"singvals_ratio.txt\"\n",
        "\n",
        "        for layer, head in selected_layer_head_list:\n",
        "\n",
        "            X = outputs.hidden_states[layer+1][sample_idx].cpu().detach().numpy() # token embeddings shape=(n_tokens_in_seq, emb_dim)=(512, 768)\n",
        "            emb_dim = X.shape[1]\n",
        "            d_k = int(emb_dim / n_heads)\n",
        "            W_q = model_params[layer_query_weight_names[layer]].data.cpu().detach().numpy()\n",
        "            W_k = model_params[layer_key_weight_names[layer]].data.cpu().detach().numpy()\n",
        "            W_v = model_params[layer_value_weight_names[layer]].data.cpu().detach().numpy()\n",
        "            W_q_i = W_q[:, head*d_k : head*d_k + d_k]\n",
        "            W_k_i = W_k[:, head*d_k : head*d_k + d_k]\n",
        "            W_v_i = W_v[:, head*d_k : head*d_k + d_k]\n",
        "\n",
        "            Q_i = np.matmul(X, W_q_i)\n",
        "            K_i = np.matmul(X, W_k_i)\n",
        "            V_i = np.matmul(X, W_v_i)\n",
        "\n",
        "            # Qi_KiT = np.matmul(Q_i, K_i.T)\n",
        "            softmax_i = torch.softmax(torch.tensor(np.matmul(Q_i, K_i.T) / math.sqrt(d_k)), dim=1).cpu().detach().numpy()\n",
        "            singular_values_softmax_i = singular_values(softmax_i)\n",
        "            mat_ratio_max_min_sv_softmax_i[layer][head] = max(singular_values_softmax_i) / min(singular_values_softmax_i)\n",
        "            secondmin_sv_softmax_i = min(np.delete(singular_values_softmax_i, singular_values_softmax_i.argmin()))\n",
        "            mat_ratio_2ndmin_min_sv_softmax_i[layer][head] = secondmin_sv_softmax_i / min(singular_values_softmax_i)\n",
        "\n",
        "            singular_values_W_v_i = singular_values(W_v_i)\n",
        "            mat_ratio_max_min_sv_W_v_i[layer][head] = max(singular_values_W_v_i) / min(singular_values_W_v_i)\n",
        "            secondmin_sv_W_v_i = min(np.delete(singular_values_W_v_i, singular_values_W_v_i.argmin()))\n",
        "            mat_ratio_2ndmin_min_sv_W_v_i[layer][head] = secondmin_sv_W_v_i / min(singular_values_W_v_i)\n",
        "\n",
        "            mat_count_zero_sv_softmax_i[layer][head] = (singular_values_softmax_i < 0.01).sum()/len(singular_values_softmax_i)\n",
        "            mat_count_zero_sv_W_v_i[layer][head] = (singular_values_W_v_i < 0.5).sum()/len(singular_values_W_v_i)\n",
        "\n",
        "            def generate_hist_sv(sv, h, l, title, histograms):\n",
        "                counts, bins = np.histogram(sv, 10)\n",
        "                if title not in histograms.keys():\n",
        "                    histograms[title] = {}\n",
        "                if h not in histograms[title].keys():\n",
        "                    histograms[title][h] = []\n",
        "                histograms[title][h].append({\n",
        "                    \"label\": f'Layer {l+1}\\n(max SV: {max(sv)})',\n",
        "                    \"counts\": counts,\n",
        "                    \"bins\": bins,\n",
        "                })\n",
        "                return histograms\n",
        "\n",
        "\n",
        "            if head in [0,4,8,9]:\n",
        "                histograms = generate_hist_sv(singular_values_softmax_i, head, layer, \"softmax\", histograms)\n",
        "                histograms = generate_hist_sv(singular_values_W_v_i, head, layer, \"W_v\", histograms)\n",
        "\n",
        "        def save_to_file(mat, fp, title, short_title, fmt, path_fig):\n",
        "            df_cols = [f\"H{x+1}\" for x in range(n_heads)]\n",
        "            df_idx = [f\"L{x+1}\" for x in range(n_layers)]\n",
        "            df = pd.DataFrame(mat, columns=df_cols)\n",
        "            df.insert(0, \"Layer\\Head\", df_idx)\n",
        "            df_tabulate = tabulate(df, headers=df.columns, showindex=False, stralign='right', floatfmt=fmt)\n",
        "            print(title)\n",
        "            print(\"=================================================================\")\n",
        "            print(df_tabulate)\n",
        "            print()\n",
        "            fp.write(f'{title}\\n=================================================================\\n')\n",
        "            fp.write(df_tabulate)\n",
        "            fp.write(\"\\n\\n\")\n",
        "            df.set_index(\"Layer\\Head\")\n",
        "            fig = plt.figure(figsize=(15,15))\n",
        "            plt.title(title)\n",
        "            sns.heatmap(mat, annot=True, fmt=fmt, yticklabels=df_idx, xticklabels=df_cols)\n",
        "            plt.show()\n",
        "            fig.savefig(Path(path_fig) / f'heatmap_{short_title}.jpg', bbox_inches='tight')\n",
        "            plt.close()\n",
        "\n",
        "\n",
        "        with open(singvals_ratio_file, 'w') as singvals_ratio_fp:\n",
        "            save_to_file(mat_ratio_max_min_sv_softmax_i, singvals_ratio_fp, \"Ratio between the highest and the lowest singular value of matrix softmax((QK^T)/d_k)\", \"ratio_max_min_sv_softmax\", '.2e', dir_path_sv)\n",
        "            save_to_file(mat_ratio_2ndmin_min_sv_softmax_i, singvals_ratio_fp, \"Ratio between the second lowest and the lowest singular value of matrix softmax((QK^T)/d_k)\", \"ratio_2ndmin_min_sv_softmax\", '.2f', dir_path_sv)\n",
        "            save_to_file(mat_ratio_max_min_sv_W_v_i, singvals_ratio_fp, \"Ratio between the highest and the lowest singular value of matrix W_v\", \"ratio_max_min_sv_Wv\", '.2f', dir_path_sv)\n",
        "            save_to_file(mat_ratio_2ndmin_min_sv_W_v_i, singvals_ratio_fp, \"Ratio between the second lowest and the lowest singular value of matrix W_v\", \"ratio_2ndmin_min_sv_Wv\", '.2f', dir_path_sv)\n",
        "            save_to_file(mat_count_zero_sv_softmax_i, singvals_ratio_fp, \"Percentage of singular values < 0.01 of matrix softmax((QK^T)/d_k)\", \"count_zero_sv_softmax\", \".2%\", dir_path_sv)\n",
        "            save_to_file(mat_count_zero_sv_W_v_i, singvals_ratio_fp, \"Percentage of singular values < 0.5 of matrix W_v\", \"count_zero_sv_Wv\", \".2%\", dir_path_sv)\n",
        "\n",
        "        def plot_hist_sv(hist_dict, title, path):\n",
        "            for h, hist_list_h in hist_dict.items():\n",
        "                fig,ax = plt.subplots(figsize=(8,8))\n",
        "                plt.title(f\"Histogram of Singular Values of {title} for head {h+1}\")\n",
        "                ax.set_xlabel(\"Singular Value\")\n",
        "                ax.set_ylabel(\"Frequency\")\n",
        "                plt.grid()\n",
        "                colors = [cm.get_cmap(\"nipy_spectral\")(i) for i in np.linspace(0, 1, n_layers)]\n",
        "                ax.set_prop_cycle(cycler('color', colors))\n",
        "                for hist in hist_list_h:\n",
        "                    ax.step(hist['bins'][:-1], hist['counts'], label=hist['label'])\n",
        "                plt.legend(bbox_to_anchor=(1.04, 1),loc='upper left')\n",
        "                plt.show()\n",
        "                fig_path = Path(path) / f'sing_val_{title}_{h+1}.jpg'\n",
        "                fig.savefig(fig_path, bbox_inches='tight')\n",
        "                plt.close()\n",
        "        \n",
        "        plot_hist_sv(histograms[\"softmax\"], \"softmax\", dir_path_sv)\n",
        "        plot_hist_sv(histograms[\"W_v\"], \"W_v\", dir_path_sv)\n",
        "                \n",
        "        return final_data_test, attentions\n",
        "\n",
        "    # elif config_dict['TASK_TYPE']=='eigenvalues_analysis':\n",
        "        \n",
        "    #     for sample_idx in range(0,len(seq_ids)):\n",
        "    #         target_label = label_ids[sample_idx]\n",
        "\n",
        "    #         if target_label == config_dict['CLASS_LABELS'][selected_class] and target_label == np.argmax(logits[sample_idx]): # correct prediction\n",
        "    #             Qi_KiT_eigvals_file = Path(math_interpret_dir) / \"von_neumann_entropy_Qi_KiT.txt\"\n",
        "    #             symm_comp_eigvals_file = Path(math_interpret_dir) / \"von_neumann_entropy_symm_comp.txt\"\n",
        "\n",
        "    #             with open(Qi_KiT_eigvals_file, 'w') as Qi_KiT_eigvals_fp, open(symm_comp_eigvals_file, 'w') as symm_comp_eigvals_fp:\n",
        "    #                 # get input embedding of sample for selected heads (shape=(n_layers, batch_dim, n_tokens_in_seq, emb_dim))\n",
        "    #                 VN_entropy_Qi_KiT_layer_sum = np.zeros(n_layers)\n",
        "    #                 VN_entropy_symm_comp_layer_sum = np.zeros(n_layers)\n",
        "    #                 Sh_entropy_Qi_KiT_layer_sum = np.zeros(n_layers)\n",
        "    #                 Sh_entropy_symm_comp_layer_sum = np.zeros(n_layers)\n",
        "    #                 count_heads_layer = np.zeros(n_layers)\n",
        "\n",
        "    #                 for layer, head in selected_layer_head_list:\n",
        "\n",
        "    #                     X = outputs.hidden_states[layer+1][sample_idx].cpu().detach().numpy() # token embeddings shape=(n_tokens_in_seq, emb_dim)=(512, 768)\n",
        "    #                     emb_dim = X.shape[1]\n",
        "    #                     d_k = int(emb_dim / n_heads)\n",
        "    #                     W_q = model_params[layer_query_weight_names[layer]].data.cpu().detach().numpy()\n",
        "    #                     W_k = model_params[layer_key_weight_names[layer]].data.cpu().detach().numpy()\n",
        "    #                     W_v = model_params[layer_value_weight_names[layer]].data.cpu().detach().numpy()\n",
        "    #                     W_q_i = W_q[:, head*d_k : head*d_k + d_k]\n",
        "    #                     W_k_i = W_k[:, head*d_k : head*d_k + d_k]\n",
        "    #                     W_v_i = W_v[:, head*d_k : head*d_k + d_k]\n",
        "\n",
        "    #                     Q_i = np.matmul(X, W_q_i)\n",
        "    #                     K_i = np.matmul(X, W_k_i)\n",
        "    #                     V_i = np.matmul(X, W_v_i)\n",
        "                        \n",
        "    #                     norm_Q_i = np.linalg.norm(Q_i, axis=1)\n",
        "    #                     norm_K_i = np.linalg.norm(K_i, axis=1)\n",
        "    #                     norm_V_i = np.linalg.norm(V_i, axis=1)\n",
        "\n",
        "    #                     singular_values_W_q_i = abs(np.linalg.svd(W_q_i, compute_uv=False))\n",
        "    #                     singular_values_W_k_i = abs(np.linalg.svd(W_k_i, compute_uv=False))\n",
        "    #                     singular_values_W_v_i = abs(np.linalg.svd(W_v_i, compute_uv=False))\n",
        "    #                     max_sv_W_q_i = max(singular_values_W_q_i)\n",
        "    #                     max_sv_W_k_i = max(singular_values_W_k_i)\n",
        "    #                     max_sv_W_v_i = max(singular_values_W_v_i)\n",
        "\n",
        "\n",
        "    #                     softmax_i = torch.softmax(torch.tensor(np.matmul(Q_i, K_i.T) / math.sqrt(d_k)), dim=1).cpu().detach().numpy()\n",
        "    #                     output_head_i = np.matmul(softmax_i, V_i)\n",
        "    #                     norm_output_head_i = np.linalg.norm(output_head_i, axis=1)\n",
        "    #                     singular_values_output_head_i = abs(np.linalg.svd(output_head_i, compute_uv=False))\n",
        "    #                     max_sv_output_head_i = max(singular_values_output_head_i)\n",
        "\n",
        "    #                     dit_path_head = Path(dir_path) / 'norm_Qi_Ki_Vi' / f'{layer+1}_{head+1}'\n",
        "    #                     if not os.path.exists(dit_path_head):\n",
        "    #                         os.makedirs(dit_path_head)\n",
        "\n",
        "    #                     # # histograms of singular values\n",
        "    #                     # fig = plt.figure(figsize=(8,8))\n",
        "    #                     # plt.hist(singular_values_W_k_i)\n",
        "    #                     # plt.title(f\"Histogram of singular values of W_k_i for head {head+1} in layer {layer+1}\")\n",
        "    #                     # plt.grid(linestyle = '--')\n",
        "    #                     # plt.yticks(list(plt.yticks()[0]) + [1])\n",
        "    #                     # plt.show()\n",
        "    #                     # dit_path_head = Path(dir_path) / 'hist_sing_val' / f'{layer+1}_{head+1}'\n",
        "    #                     # if not os.path.exists(dit_path_head):\n",
        "    #                     #     os.makedirs(dit_path_head)\n",
        "    #                     # fig_path = Path(dit_path_head) / f'{layer+1}_{head+1}.jpg'\n",
        "    #                     # fig.savefig(fig_path, bbox_inches='tight')\n",
        "    #                     # plt.close()\n",
        "\n",
        "    #                     # # histograms of norms of Q_i\n",
        "    #                     # fig,ax = plt.subplots(figsize=(8,8))\n",
        "    #                     # plt.hist(norm_Q_i)\n",
        "    #                     # plt.title(f\"Histogram of the norms of Q_i for head {head+1} in layer {layer+1}\\n(max SV of W_q_i: {max_sv_W_q_i})\")\n",
        "    #                     # plt.grid(linestyle = '--')\n",
        "    #                     # ax.set_xlabel(\"Norm of Q_i\")\n",
        "    #                     # ax.set_ylabel(\"Frequency\")\n",
        "    #                     # plt.show()\n",
        "    #                     # fig_path = Path(dit_path_head) / f'norm_Qi_{layer+1}_{head+1}.jpg'\n",
        "    #                     # fig.savefig(fig_path, bbox_inches='tight')\n",
        "    #                     # plt.close()\n",
        "\n",
        "    #                     # # histograms of norms of K_i\n",
        "    #                     # fig,ax = plt.subplots(figsize=(8,8))\n",
        "    #                     # plt.hist(norm_K_i)\n",
        "    #                     # plt.title(f\"Histogram of the norms of K_i for head {head+1} in layer {layer+1}\\n(max SV of W_k_i: {max_sv_W_k_i})\")\n",
        "    #                     # plt.grid(linestyle = '--')\n",
        "    #                     # ax.set_xlabel(\"Norm of K_i\")\n",
        "    #                     # ax.set_ylabel(\"Frequency\")\n",
        "    #                     # plt.show()\n",
        "    #                     # fig_path = Path(dit_path_head) / f'norm_Ki_{layer+1}_{head+1}.jpg'\n",
        "    #                     # fig.savefig(fig_path, bbox_inches='tight')\n",
        "    #                     # plt.close()\n",
        "\n",
        "    #                     # # histograms of norms of V_i\n",
        "    #                     # fig,ax = plt.subplots(figsize=(8,8))\n",
        "    #                     # plt.hist(norm_V_i)\n",
        "    #                     # plt.title(f\"Histogram of the norms of V_i for head {head+1} in layer {layer+1}\\n(max SV of W_v_i: {max_sv_W_v_i})\")\n",
        "    #                     # plt.grid(linestyle = '--')\n",
        "    #                     # ax.set_xlabel(\"Norm of V_i\")\n",
        "    #                     # ax.set_ylabel(\"Frequency\")\n",
        "    #                     # plt.show()\n",
        "    #                     # fig_path = Path(dit_path_head) / f'norm_Vi_{layer+1}_{head+1}.jpg'\n",
        "    #                     # fig.savefig(fig_path, bbox_inches='tight')\n",
        "    #                     # plt.close()\n",
        "\n",
        "\n",
        "    #                     # # histograms of norms of output_head_i\n",
        "    #                     # fig,ax = plt.subplots(figsize=(8,8))\n",
        "    #                     # plt.hist(norm_output_head_i)\n",
        "    #                     # plt.title(f\"Histogram of the norms of Y_i output for head {head+1} in layer {layer+1}\\n(max SV of Y_i: {max_sv_output_head_i})\")\n",
        "    #                     # plt.grid(linestyle = '--')\n",
        "    #                     # ax.set_xlabel(\"Norm of Y_i\")\n",
        "    #                     # ax.set_ylabel(\"Frequency\")\n",
        "    #                     # plt.show()\n",
        "    #                     # fig_path = Path(dit_path_head) / f'norm_Yi_{layer+1}_{head+1}.jpg'\n",
        "    #                     # fig.savefig(fig_path, bbox_inches='tight')\n",
        "    #                     # plt.close()\n",
        "\n",
        "\n",
        "    #                     # histogram of singular values of output_head_i\n",
        "    #                     fig,ax = plt.subplots(figsize=(8,8))\n",
        "    #                     plt.hist(singular_values_output_head_i)\n",
        "    #                     plt.title(f\"Histogram of Singular Values of Y_i output for head {head+1} in layer {layer+1}\\n(max SV of Y_i: {max_sv_output_head_i})\")\n",
        "    #                     plt.grid(linestyle = '--')\n",
        "    #                     ax.set_xlabel(\"Norm of Y_i\")\n",
        "    #                     ax.set_ylabel(\"Frequency\")\n",
        "    #                     plt.show()\n",
        "    #                     fig_path = Path(dit_path_head) / f'sing_val_Yi_{layer+1}_{head+1}.jpg'\n",
        "    #                     fig.savefig(fig_path, bbox_inches='tight')\n",
        "    #                     plt.close()\n",
        "\n",
        "\n",
        "    #                 #     # Von Neumann norms\n",
        "    #                 #     count_heads_layer[layer] += 1\n",
        "    #                 #     # Eigenvalues of QK^T\n",
        "    #                 #     Qi_KiT = np.matmul(Q_i, K_i.T)\n",
        "    #                 #     eigvals_Qi_KiT = np.linalg.eigvals(Qi_KiT)\n",
        "    #                 #     n_eigvals_zero_Qi_KiT = f\"{len(eigvals_Qi_KiT) - np.count_nonzero(eigvals_Qi_KiT)}/{len(eigvals_Qi_KiT)}\"\n",
        "    #                 #     # von neumann entropy and shannon entropy\n",
        "    #                 #     VN_entropy_Qi_KiT = compute_Von_Neumann_entropy_eigvals(Qi_KiT, f\"head{head+1}_layer_{layer+1}\")\n",
        "    #                 #     Sh_entropy_Qi_KiT = compute_Shannon_entropy(Qi_KiT, f\"head{head+1}_layer_{layer+1}\")\n",
        "    #                 #     Qi_KiT_eigvals_fp.write(f\"\\thead_{head+1}_layer_{layer+1} | n_eigv_zero={n_eigvals_zero_Qi_KiT} | VN_entropy_={VN_entropy_Qi_KiT}\\n\")\n",
        "    #                 #     VN_entropy_Qi_KiT_layer_sum[layer] += VN_entropy_Qi_KiT\n",
        "    #                 #     Sh_entropy_Qi_KiT_layer_sum[layer] += Sh_entropy_Qi_KiT\n",
        "\n",
        "    #                 #     # Eigenvalues of symmetric component\n",
        "    #                 #     symm_comp_mat = (Qi_KiT + Qi_KiT.T) / 2\n",
        "    #                 #     eigvals_symm_comp_mat = np.linalg.eigvals(symm_comp_mat)\n",
        "    #                 #     n_eigvals_zero_symm_comp_mat = f\"{len(eigvals_symm_comp_mat) - np.count_nonzero(eigvals_symm_comp_mat)}/{len(eigvals_symm_comp_mat)}\"\n",
        "    #                 #     # von neumann entropy\n",
        "    #                 #     VN_entropy_symm_comp_mat = compute_Von_Neumann_entropy_eigvals(symm_comp_mat, f\"head{head+1}_layer_{layer+1}\")\n",
        "    #                 #     Sh_entropy_symm_comp_mat = compute_Shannon_entropy(symm_comp_mat, f\"head{head+1}_layer_{layer+1}\")\n",
        "    #                 #     symm_comp_eigvals_fp.write(f\"\\thead_{head+1}_layer_{layer+1} | n_eigv_zero={n_eigvals_zero_symm_comp_mat} | VN_entropy_head_{head+1}layer_{layer+1} = {VN_entropy_symm_comp_mat}\\n\")\n",
        "    #                 #     VN_entropy_symm_comp_layer_sum[layer] += VN_entropy_symm_comp_mat\n",
        "    #                 #     Sh_entropy_symm_comp_layer_sum[layer] += Sh_entropy_symm_comp_mat\n",
        "\n",
        "    #                 # VN_entropy_Qi_KiT_layer_mean = VN_entropy_Qi_KiT_layer_sum / count_heads_layer\n",
        "    #                 # VN_entropy_symm_comp_layer_mean = VN_entropy_symm_comp_layer_sum / count_heads_layer\n",
        "    #                 # Sh_entropy_Qi_KiT_layer_mean = Sh_entropy_Qi_KiT_layer_sum / count_heads_layer\n",
        "    #                 # Sh_entropy_symm_comp_layer_mean = Sh_entropy_symm_comp_layer_sum / count_heads_layer\n",
        "    #                 # fig = plt.figure(figsize=(10,10))\n",
        "    #                 # x = [i+1 for i in range(n_layers)]\n",
        "    #                 # fig, ax = plt.subplots()\n",
        "    #                 # ax.plot(x, VN_entropy_Qi_KiT_layer_mean, 'b', label='VN entropy of QiKi^T')\n",
        "    #                 # ax.plot(x, VN_entropy_symm_comp_layer_mean, 'r', label='VN entropy of QiKi^T symm. comp.')\n",
        "    #                 # ax.axis('equal')\n",
        "    #                 # leg = ax.legend()\n",
        "    #                 # plt.title(f\"Average Von Neumann entropy for each layer\")\n",
        "    #                 # plt.grid(linestyle = '--')\n",
        "    #                 # ax.set_xticks(x)\n",
        "    #                 # #fig.yticks(list(plt.yticks()[0]) + [1])\n",
        "    #                 # ax.set_xlabel(\"Layer\")\n",
        "    #                 # ax.set_ylabel(\"VN entropy\")\n",
        "    #                 # plt.show()\n",
        "    #                 # fig_path = Path(dir_path) / f'VN_entropy_plot.jpg'\n",
        "    #                 # fig.savefig(fig_path, bbox_inches='tight')\n",
        "    #                 # plt.close()\n",
        "\n",
        "    #                 # fig = plt.figure(figsize=(10,10))\n",
        "    #                 # x = [i+1 for i in range(n_layers)]\n",
        "    #                 # fig, ax = plt.subplots()\n",
        "    #                 # ax.plot(x, Sh_entropy_Qi_KiT_layer_mean, 'b', label='Shannon entropy of QiKi^T')\n",
        "    #                 # ax.plot(x, Sh_entropy_symm_comp_layer_mean, 'r', label='Shannon entropy of QiKi^T symm. comp.')\n",
        "    #                 # ax.axis('equal')\n",
        "    #                 # leg = ax.legend()\n",
        "    #                 # plt.title(f\"Average Shannon entropy for each layer\")\n",
        "    #                 # plt.grid(linestyle = '--')\n",
        "    #                 # ax.set_xticks(x)\n",
        "    #                 # #fig.yticks(list(plt.yticks()[0]) + [1])\n",
        "    #                 # ax.set_xlabel(\"Layer\")\n",
        "    #                 # ax.set_ylabel(\"Shannon entropy\")\n",
        "    #                 # plt.show()\n",
        "    #                 # fig_path = Path(dir_path) / f'Shannon_entropy_plot.jpg'\n",
        "    #                 # fig.savefig(fig_path, bbox_inches='tight')\n",
        "    #                 # plt.close()\n",
        "\n",
        "    #             return final_data_test, test_accuracies, attentions, timings\n",
        "\n",
        "    # if config_dict['TASK_TYPE']=='attention_analysis' or config_dict['TASK_TYPE']=='attention_flow':\n",
        "    #     # calculate mean of attention matrices:\n",
        "    #     for target_label in config_dict['CLASS_LABELS'].values():\n",
        "    #         for layer in range(len(attentions_all_layers[target_label])):\n",
        "    #             for head in range(len(attentions_all_layers[target_label][layer])):\n",
        "    #                 attentions_all_layers[target_label][layer][head] = attentions_all_layers[target_label][layer][head] / count_class_samples[target_label]\n",
        "\n",
        "\n",
        "    if config_dict['TASK_TYPE']=='distance_cones_analysis':\n",
        "        dist_cones_path = Path(math_interpret_dir) / 'direction_cones'\n",
        "        if not os.path.exists(dist_cones_path):\n",
        "            os.makedirs(dist_cones_path)\n",
        "        \n",
        "        fig, ax = plt.subplots(figsize=((7,4)))\n",
        "        ax.plot(list(distance_cones_1_sample.keys()), list(distance_cones_1_sample.values()), '-o')\n",
        "        ax.set_title('Cone index')\n",
        "        ax.set_xlabel(\"Layer\")\n",
        "        ax.set_ylabel(\"Index\")\n",
        "        ax.set_xticks(list(distance_cones_1_sample.keys()))\n",
        "        ax.set_xticklabels(np.asarray(list(distance_cones_1_sample.keys()))+1)\n",
        "        ax.grid()\n",
        "        plt.show()\n",
        "        fig_path = Path(dist_cones_path) / f'cone_index_{title}.jpg'\n",
        "        fig.savefig(fig_path)\n",
        "        fig.clear()\n",
        "\n",
        "        # for layer, layer_distance_cones in distance_cones.items():\n",
        "        #     n_bins=20\n",
        "        #     distance_cones_1 = {k:v for k,v in layer_distance_cones.items() if k in ['Layer input', 'Multihead output', 'Layer output']}\n",
        "        #     fig, ax = plt.subplots(figsize=((7,4)))\n",
        "        #     ax.hist(distance_cones_1.values(), n_bins, histtype='step', stacked=True, fill=False, label=layer_distance_cones.keys())\n",
        "        #     ax.set_title(f'L{layer} cone index')\n",
        "        #     ax.legend(prop={'size': 10})\n",
        "        #     ax.set_xlabel(\"Cone index\")\n",
        "        #     ax.set_ylabel(\"Frequency\")\n",
        "        #     box = ax.get_position()\n",
        "        #     ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
        "        #     ax.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
        "        #     plt.show()\n",
        "        #     fig_path = Path(dist_cones_path) / f'direction_cones_L{layer}_1.jpg'\n",
        "        #     fig.savefig(fig_path)\n",
        "        #     fig.clear()\n",
        "\n",
        "        #     distance_cones_2 = {k:v for k,v in layer_distance_cones.items() if k in ['Layer input', 'Head output']}\n",
        "        #     fig, ax = plt.subplots(figsize=((7,4)))\n",
        "        #     ax.hist(distance_cones_2.values(), n_bins, histtype='step', stacked=True, fill=False, label=layer_distance_cones.keys())\n",
        "        #     ax.set_title(f'L{layer} cone index')\n",
        "        #     ax.legend(prop={'size': 10})\n",
        "        #     ax.set_xlabel(\"Cone index\")\n",
        "        #     ax.set_ylabel(\"Frequency\")\n",
        "        #     box = ax.get_position()\n",
        "        #     ax.set_position([box.x0, box.y0, box.width * 0.8, box.height])\n",
        "        #     ax.legend(bbox_to_anchor=(1.04,1), loc=\"upper left\")\n",
        "        #     plt.show()\n",
        "        #     fig_path = Path(dist_cones_path) / f'direction_cones_L{layer}_2.jpg'\n",
        "        #     fig.savefig(fig_path)\n",
        "        #     fig.clear()\n",
        "\n",
        "\n",
        "    print('DONE.')\n",
        "\n",
        "    # token_base_positions_axis = [f\"{i*config_dict['STRIDE']-config_dict['STRIDE']+spike_gene_start}\" for i in range(0,config_dict['MAX_LENGTH'])]\n",
        "\n",
        "    attentions = {'attentions_all_layers' : attentions_all_layers,\n",
        "                  'attentions_all_layers_thresh' : attentions_all_layers_thresh,\n",
        "                  'repr_token_base_positions_axis' : repr_token_base_positions_axis\n",
        "                  }\n",
        "\n",
        "    return final_data_test, attentions\n",
        "\n",
        "def show_test_plots(accuracies):\n",
        "    # Create a barplot showing the accuracy score for each batch of test samples.\n",
        "    fig = plt.figure(figsize=(12,6))\n",
        "    ax = sns.lineplot(x=list(range(len(accuracies))), y=accuracies, ci=None)\n",
        "\n",
        "    plt.title('Accuracy per Batch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Batch #')\n",
        "\n",
        "    plt.show()\n",
        "    fig_path = Path(outputs_dir) / 'test.jpg'\n",
        "    fig.savefig(fig_path)\n",
        "\n",
        "\n",
        "def plot_color_gradients(cmap_list, labels=None, title=''):\n",
        "    # Create figure and adjust figure height to number of colormaps\n",
        "    nrows = len(cmap_list)\n",
        "    figh = 0.35 + 0.15 + (nrows + (nrows-1)*0.1)*0.22\n",
        "    fig, axs = plt.subplots(nrows=nrows, figsize=(6.4, figh))\n",
        "    fig.subplots_adjust(top=1-.35/figh, bottom=.15/figh, left=0.2, right=0.99)\n",
        "\n",
        "    axs[0].set_title(title, fontsize=14)\n",
        "    gradient = np.linspace(0, 1, 256)\n",
        "    gradient = np.vstack((gradient, gradient))\n",
        "\n",
        "    i=0\n",
        "    for ax, cmap_name in zip(axs, cmap_list):\n",
        "        if labels == None:\n",
        "            ax.imshow(gradient, aspect='auto', cmap=cmap_name)\n",
        "            ax.text(-.01, .5, f'{i}', va='center', ha='right', fontsize=10,\n",
        "                transform=ax.transAxes)\n",
        "        else:\n",
        "            if i not in labels:\n",
        "                break\n",
        "            ax.imshow(gradient, aspect='auto', cmap=cmap_name)\n",
        "            ax.text(-.01, .5, f'{labels[i]}', va='center', ha='right', fontsize=10,\n",
        "                transform=ax.transAxes)\n",
        "        i+=1\n",
        "\n",
        "    # Turn off *all* ticks & spines, not just the ones with colormaps.\n",
        "    for ax in axs:\n",
        "        ax.set_axis_off()\n",
        "        \n",
        "    plt.show()\n",
        "    fig_path = Path(attention_matrices_dir) / f'{title}.jpg'\n",
        "    fig.savefig(fig_path, bbox_inches='tight', pad_inches=0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5c5m5d7vkPJg"
      },
      "outputs": [],
      "source": [
        "# bins = pd.cut(mat.ravel(), bins=20)\n",
        "#     shannon_entropy=0\n",
        "#     tot_count = len(mat.ravel())\n",
        "#     pjs = pd.value_counts(bins) / tot_countdicta = {'a': [1,2,3,4], 'b': [1,3,5,7], \"c\": [5,12,13]}\n",
        "# lista = []\n",
        "# for k, v in dicta.items():\n",
        "#     lista.extend(v)\n",
        "# unique, count = np.unique(lista, return_counts= True)\n",
        "# list1occ = [x for idx, x in enumerate(unique) if count[idx]==1]\n",
        "# dictaf = {k:[x for x in v if x in list1occ] for k,v in dicta.items()}\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xxcgT9ogVW7U"
      },
      "source": [
        "#### Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Om9LG4uSEfy"
      },
      "outputs": [],
      "source": [
        "if do_test:\n",
        "    if config_dict['TASK_TYPE']=='eigenvalues_analysis' or config_dict['TASK_TYPE']=='attention_analysis' or config_dict['TASK_TYPE']=='singularvalues_ratio_analysis' or config_dict['TASK_TYPE']=='distance_cones_analysis' or config_dict['TASK_TYPE']=='layer_output_analysis':\n",
        "        selected_layer_head_list = config_dict['SELECTED_LAYER_HEAD_LIST']\n",
        "        \n",
        "    with open(log_file, 'a') as log_fp:\n",
        "        attention_cases = []\n",
        "        input_embs_identity = torch.ones(config_dict['MAX_LENGTH'] , config_dict['EMB_DIM'])\n",
        "        input_embs_identity = input_embs_identity[None, :]  # add one dummy dimension, representing batch\n",
        "        print(\"\\n------- Identity embeddings, base model -------\")\n",
        "        _, attentions_id_base = supervisedBertClassifierTest(\n",
        "            input_embs_identity,\n",
        "            model_base, \n",
        "            log_fp, \n",
        "            config_dict['THETA'], \n",
        "            selected_layer_head_list=selected_layer_head_list, \n",
        "            dir_path=math_interpret_dir,\n",
        "            title=\"identity_embeddings_base_model\"\n",
        "            )\n",
        "        attention_cases.append({\n",
        "            'title': \"identity_embeddings_base_model\",\n",
        "            'attentions_dict': attentions_id_base\n",
        "            })\n",
        "        \n",
        "        print(\"\\n------- Identity embeddings, fine-tuned model -------\")\n",
        "        _, attentions_id_finetuned = supervisedBertClassifierTest(\n",
        "            input_embs_identity,\n",
        "            model_finetuned, \n",
        "            log_fp, \n",
        "            config_dict['THETA'], \n",
        "            selected_layer_head_list=selected_layer_head_list, \n",
        "            dir_path=math_interpret_dir,\n",
        "            title=\"identity_embeddings_finetuned_model\"\n",
        "            )\n",
        "        attention_cases.append({\n",
        "            'title': \"identity_embeddings_finetuned_model\",\n",
        "            'attentions_dict': attentions_id_finetuned\n",
        "            })\n",
        "        \n",
        "        input_embs_randn = torch.randn(config_dict['MAX_LENGTH'] , config_dict['EMB_DIM'])\n",
        "        input_embs_randn = input_embs_randn[None, :]  # add one dummy dimension, representing batch\n",
        "        print(\"\\n------- White noise embeddings, base model -------\")\n",
        "        _, attentions_rand_base = supervisedBertClassifierTest(\n",
        "            input_embs_randn,\n",
        "            model_base, \n",
        "            log_fp, \n",
        "            config_dict['THETA'], \n",
        "            selected_layer_head_list=selected_layer_head_list, \n",
        "            dir_path=math_interpret_dir,\n",
        "            title=\"whitenoise_embeddings_base_model\"\n",
        "            )\n",
        "        attention_cases.append({\n",
        "            'title': \"whitenoise_embeddings_base_model\",\n",
        "            'attentions_dict': attentions_rand_base\n",
        "            })\n",
        "        \n",
        "        print(\"\\n------- White noise embeddings, fine-tuned model -------\")\n",
        "        _, attentions_rand_finetuned = supervisedBertClassifierTest(\n",
        "            input_embs_randn,\n",
        "            model_finetuned, \n",
        "            log_fp, \n",
        "            config_dict['THETA'], \n",
        "            selected_layer_head_list=selected_layer_head_list, \n",
        "            dir_path=math_interpret_dir,\n",
        "            title=\"whitenoise_embeddings_finetuned_model\"\n",
        "            )\n",
        "        attention_cases.append({\n",
        "            'title': \"whitenoise_embeddings_finetuned_model\",\n",
        "            'attentions_dict': attentions_rand_finetuned\n",
        "            })\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g6b_5g2QCs28"
      },
      "source": [
        "###Attention analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xWTnELSGgaQI"
      },
      "outputs": [],
      "source": [
        "def get_attentions_for_case(attention_case):    \n",
        "    if config_dict['TASK_TYPE']=='attention_analysis' or config_dict['TASK_TYPE']=='attention_flow' or config_dict['TASK_TYPE']=='von_neumann_entropy_attentions' or config_dict['TASK_TYPE']=='shannon_entropy_attentions':\n",
        "\n",
        "        attention_matrices_file = Path(attention_matrices_dir) / f\"{attention_case['title']}_attention_matrices_np\"\n",
        "        attention_matrices_thresh_file = Path(attention_matrices_dir) / f\"{attention_case['title']}_attention_matrices_thresh_np\"\n",
        "        ticks_file = Path(attention_matrices_dir) / f\"{attention_case['title']}_ticks_np\"\n",
        "        attentions2 = {}\n",
        "\n",
        "        if os.path.exists(attention_matrices_file):\n",
        "            attentions2['attentions_all_layers'] = pickle.load(open(attention_matrices_file, 'rb'))\n",
        "        else: \n",
        "            pickle.dump(attention_case['attentions_dict']['attentions_all_layers'], open(attention_matrices_file, 'wb'))\n",
        "            attentions2['attentions_all_layers'] = attention_case['attentions_dict']['attentions_all_layers']\n",
        "\n",
        "        if os.path.exists(attention_matrices_thresh_file):\n",
        "            attentions2['attentions_all_layers_thresh'] = pickle.load(open(attention_matrices_thresh_file, 'rb'))\n",
        "        else: \n",
        "            pickle.dump(attention_case['attentions_dict']['attentions_all_layers_thresh'], open(attention_matrices_thresh_file, 'wb'))\n",
        "            attentions2['attentions_all_layers_thresh'] = attention_case['attentions_dict']['attentions_all_layers_thresh']\n",
        "\n",
        "        if os.path.exists(ticks_file):\n",
        "            attentions2['repr_token_base_positions_axis'] = pickle.load(open(ticks_file, 'rb'))\n",
        "        else: \n",
        "            pickle.dump(attention_case['attentions_dict']['repr_token_base_positions_axis'], open(ticks_file, 'wb'))\n",
        "            attentions2['repr_token_base_positions_axis'] = attention_case['attentions_dict']['repr_token_base_positions_axis']\n",
        "        \n",
        "        return attentions2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CbW86Qc0nUGX"
      },
      "outputs": [],
      "source": [
        "# np.asarray(attentions2['attentions_all_layers'][7][9][11]).max()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzgnLrEvAyI4"
      },
      "outputs": [],
      "source": [
        "def attention_analysis(attentions, log_fp_test, theta=0, selected_layers=None, selected_heads=None, title=None):\n",
        "    # token_base_positions_axis = attentions['token_base_positions_axis']\n",
        "    # attentions_last_layer = attentions['attentions_last_layer']\n",
        "    attentions_all_layers = attentions['attentions_all_layers'] if 'attentions_all_layers' in attentions.keys() else None\n",
        "    attentions_all_layers_thresh = attentions['attentions_all_layers_thresh']\n",
        "    repr_token_base_positions_axis = attentions['repr_token_base_positions_axis']\n",
        "    \n",
        "    attn_last_layers_sum_dir = Path(attention_matrices_dir) / \"last_layers_sum\"\n",
        "\n",
        "    for layer in selected_layers:\n",
        "        if selected_heads == 'avg':\n",
        "            #calculate the avg of attention matrices of heads of current layer\n",
        "            attn_mat = attentions_all_layers[layer].mean(dim=0).cpu().detach().numpy() \n",
        "            plt_attentions(attn_mat, \n",
        "                        repr_token_base_positions_axis, \n",
        "                        attn_last_layers_sum_dir, \n",
        "                        theta=theta,\n",
        "                        filename=f\"{title}_{layer+1}\",\n",
        "                        title=f\"Average of attention matrices of heads of layer {layer+1} for the case '{title}', theta = {theta:.3f}\",\n",
        "                        # cmap=colormaps_layers[layer]\n",
        "                        ) \n",
        "        else:\n",
        "            for head in selected_heads:\n",
        "                attn_mat = attentions_all_layers[layer][head].cpu().detach().numpy() \n",
        "                plt_attentions(attn_mat, \n",
        "                        repr_token_base_positions_axis, \n",
        "                        attn_last_layers_sum_dir, \n",
        "                        theta=theta,\n",
        "                        filename=f\"{title}_{layer+1}_{head+1}\",\n",
        "                        title=f\"Attention matrix of head {head+1} of layer {layer+1}  for the case '{title}', theta = {theta:.3f}\",\n",
        "                        # cmap=colormaps_layers[layer]\n",
        "                        ) \n",
        "\n",
        "def attention_analysis_proportions(attentions, log_fp_test, theta=0):\n",
        "    attentions_all_layers = attentions['attentions_all_layers'] if 'attentions_all_layers' in attentions.keys() else None\n",
        "    # attentions_all_layers_thresh = attentions['attentions_all_layers_thresh']\n",
        "    ##### ATTENTIONS BY DOMAIN ######\n",
        "    show_attentions_for_each_domain(attentions_all_layers, proportion_attn_domains_dir, proportion=\"attention\")\n",
        "    # show_attentions_for_each_domain(attentions_all_layers_thresh, proportion_attn_domains_dir, proportion=\"high-attention-tokens-count\", theta=theta)\n",
        "    # attention_pct, pvalues = top_heads_attention_proportions(attentions_all_layers_thresh, proportion=\"high-confidence-attention\", min_total=0, theta=theta)\n",
        "    # print(f\"\\nPercentages of attention of maximally attentive heads:\\n\")\n",
        "    # print(attention_pct.to_markdown())\n",
        "    # print(f\"\\nP-values of attention of maximally attentive heads with respect to background frequencies:\\n\")\n",
        "    # print(pvalues.to_markdown())\n",
        "    # log_fp_test.write(f\"\\nP-values of attention of maximally attentive heads with respect to background frequencies:\\n\")\n",
        "    # log_fp_test.write(f\"{pvalues.to_markdown()}\\n\")\n",
        "    # log_fp_test.write(f\"\\nPercentages of attention of maximally attentive heads:\\n\")\n",
        "    # log_fp_test.write(f\"{attention_pct.to_markdown()}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_HDUJ_T1F8E"
      },
      "outputs": [],
      "source": [
        "if config_dict['TASK_TYPE']=='attention_analysis':\n",
        "    with open(log_file, 'a') as log_fp:\n",
        "        for attention_case in attention_cases:\n",
        "            attentions2 = get_attentions_for_case(attention_case)\n",
        "            print(attentions2['repr_token_base_positions_axis'])\n",
        "            selected_layers = range(n_layers) #[10] #range(n_layers)\n",
        "            selected_heads = range(n_heads) #[4] #range(n_heads) #'avg'\n",
        "            theta_plot = 0.01 #0.01\n",
        "            attention_analysis(attentions2, log_fp, theta_plot, selected_layers, selected_heads, attention_case['title'])\n",
        "            #attention_analysis_proportions(attentions2, log_fp) #theta=0.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEAkAWrVv9Nb"
      },
      "source": [
        "### Attention flow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8BsO_mdUwAGP"
      },
      "outputs": [],
      "source": [
        "#@title Utilities\n",
        "\n",
        "def get_adjmat(mat, input_tokens):\n",
        "    n_layers, length, _ = mat.shape\n",
        "    adj_mat = np.zeros(((n_layers+1)*length, (n_layers+1)*length))\n",
        "    labels_to_index = {}\n",
        "    for k in np.arange(length):\n",
        "        labels_to_index[str(k)+\"_\"+input_tokens[k]] = k\n",
        "\n",
        "    for i in np.arange(1,n_layers+1):\n",
        "        for k_f in np.arange(length):\n",
        "            index_from = (i)*length+k_f\n",
        "            label = \"L\"+str(i)+\"_\"+str(k_f)\n",
        "            labels_to_index[label] = index_from\n",
        "            for k_t in np.arange(length):\n",
        "                index_to = (i-1)*length+k_t\n",
        "                adj_mat[index_from][index_to] = mat[i-1][k_f][k_t]\n",
        "                \n",
        "    return adj_mat, labels_to_index \n",
        "\n",
        "\n",
        "def draw_attention_graph(adjmat, labels_to_index, n_layers, length):\n",
        "    A = adjmat\n",
        "    G=nx.from_numpy_matrix(A, create_using=nx.DiGraph())\n",
        "    for i in np.arange(A.shape[0]):\n",
        "        for j in np.arange(A.shape[1]):\n",
        "            nx.set_edge_attributes(G, {(i,j): A[i,j]}, 'capacity')\n",
        "\n",
        "    pos = {}\n",
        "    label_pos = {}\n",
        "    for i in np.arange(n_layers+1):\n",
        "        for k_f in np.arange(length):\n",
        "            pos[i*length+k_f] = ((i+0.5)*2, length - k_f)\n",
        "            label_pos[i*length+k_f] = (i*2, length - k_f)\n",
        "\n",
        "    index_to_labels = {}\n",
        "    for key in labels_to_index:\n",
        "        index_to_labels[labels_to_index[key]] = key.split(\"_\")[-1]\n",
        "        if labels_to_index[key] >= length:\n",
        "            index_to_labels[labels_to_index[key]] = ''\n",
        "\n",
        "    #plt.figure(1,figsize=(20,12))\n",
        "\n",
        "    nx.draw_networkx_nodes(G,pos,node_color='green', node_size=50)\n",
        "    nx.draw_networkx_labels(G,pos=label_pos, labels=index_to_labels, font_size=10)\n",
        "\n",
        "    all_weights = []\n",
        "    #4 a. Iterate through the graph nodes to gather all the weights\n",
        "    for (node1,node2,data) in G.edges(data=True):\n",
        "        all_weights.append(data['weight']) #we'll use this when determining edge thickness\n",
        "\n",
        "    #4 b. Get unique weights\n",
        "    unique_weights = list(set(all_weights))\n",
        "\n",
        "    #4 c. Plot the edges - one by one!\n",
        "    print(\"Plot the edges - one by one!\")\n",
        "    for weight in tqdm(unique_weights):\n",
        "        #4 d. Form a filtered list with just the weight you want to draw\n",
        "        weighted_edges = [(node1,node2) for (node1,node2,edge_attr) in G.edges(data=True) if edge_attr['weight']==weight]\n",
        "        #4 e. I think multiplying by [num_nodes/sum(all_weights)] makes the graphs edges look cleaner\n",
        "        \n",
        "        w = weight #(weight - min(all_weights))/(max(all_weights) - min(all_weights))\n",
        "        width = w\n",
        "        nx.draw_networkx_edges(G,pos,edgelist=weighted_edges,width=width, edge_color='darkblue')\n",
        "    \n",
        "    return G\n",
        "\n",
        "def get_attention_graph(adjmat, labels_to_index, n_layers, length):\n",
        "    A = adjmat\n",
        "    G=nx.from_numpy_matrix(A, create_using=nx.DiGraph())\n",
        "    for i in np.arange(A.shape[0]):\n",
        "        for j in np.arange(A.shape[1]):\n",
        "            nx.set_edge_attributes(G, {(i,j): A[i,j]}, 'capacity')\n",
        "\n",
        "    pos = {}\n",
        "    label_pos = {}\n",
        "    for i in np.arange(n_layers+1):\n",
        "        for k_f in np.arange(length):\n",
        "            pos[i*length+k_f] = ((i+0.5)*2, length - k_f)\n",
        "            label_pos[i*length+k_f] = (i*2, length - k_f)\n",
        "\n",
        "    index_to_labels = {}\n",
        "    for key in labels_to_index:\n",
        "        index_to_labels[labels_to_index[key]] = key.split(\"_\")[-1]\n",
        "        if labels_to_index[key] >= length:\n",
        "            index_to_labels[labels_to_index[key]] = ''\n",
        "\n",
        "    #plt.figure(1,figsize=(20,12))\n",
        "\n",
        "    nx.draw_networkx_nodes(G,pos,node_color='green', node_size=50)\n",
        "    nx.draw_networkx_labels(G,pos=label_pos, labels=index_to_labels, font_size=10)\n",
        "\n",
        "    all_weights = []\n",
        "    #4 a. Iterate through the graph nodes to gather all the weights\n",
        "    for (node1,node2,data) in G.edges(data=True):\n",
        "        all_weights.append(data['weight']) #we'll use this when determining edge thickness\n",
        "\n",
        "    #4 b. Get unique weights\n",
        "    unique_weights = list(set(all_weights))\n",
        "\n",
        "    #4 c. Plot the edges - one by one!\n",
        "    for weight in unique_weights:\n",
        "        #4 d. Form a filtered list with just the weight you want to draw\n",
        "        weighted_edges = [(node1,node2) for (node1,node2,edge_attr) in G.edges(data=True) if edge_attr['weight']==weight]\n",
        "        #4 e. I think multiplying by [num_nodes/sum(all_weights)] makes the graphs edges look cleaner\n",
        "        \n",
        "        w = weight #(weight - min(all_weights))/(max(all_weights) - min(all_weights))\n",
        "        width = w\n",
        "        nx.draw_networkx_edges(G,pos,edgelist=weighted_edges,width=width, edge_color='darkblue')\n",
        "    \n",
        "    return G\n",
        "\n",
        "def compute_flows(G, labels_to_index, input_nodes, length):\n",
        "    print(\"Computing flows\")\n",
        "    number_of_nodes = len(labels_to_index)\n",
        "    flow_values=np.zeros((number_of_nodes,number_of_nodes))\n",
        "    for key in tqdm(labels_to_index):\n",
        "        if key not in input_nodes:\n",
        "            current_layer = int(labels_to_index[key] / length)\n",
        "            pre_layer = current_layer - 1\n",
        "            u = labels_to_index[key]\n",
        "            for inp_node_key in input_nodes:\n",
        "                v = labels_to_index[inp_node_key]\n",
        "                flow_value = nx.maximum_flow_value(G,u,v, flow_func=nx.algorithms.flow.edmonds_karp)\n",
        "                flow_values[u][pre_layer*length+v ] = flow_value\n",
        "            flow_values[u] /= flow_values[u].sum()\n",
        "            \n",
        "    return flow_values\n",
        "\n",
        "def compute_node_flow(G, labels_to_index, input_nodes, output_nodes,length):\n",
        "    number_of_nodes = len(labels_to_index)\n",
        "    flow_values=np.zeros((number_of_nodes,number_of_nodes))\n",
        "    for key in output_nodes:\n",
        "        if key not in input_nodes:\n",
        "            current_layer = int(labels_to_index[key] / length)\n",
        "            pre_layer = current_layer - 1\n",
        "            u = labels_to_index[key]\n",
        "            for inp_node_key in input_nodes:\n",
        "                v = labels_to_index[inp_node_key]\n",
        "                flow_value = nx.maximum_flow_value(G,u,v, flow_func=nx.algorithms.flow.edmonds_karp)\n",
        "                flow_values[u][pre_layer*length+v ] = flow_value\n",
        "            flow_values[u] /= flow_values[u].sum()\n",
        "            \n",
        "    return flow_values\n",
        "\n",
        "def compute_joint_attention(att_mat, add_residual=True):\n",
        "    if add_residual:\n",
        "        residual_att = np.eye(att_mat.shape[1])[None,...]\n",
        "        aug_att_mat = att_mat + residual_att\n",
        "        aug_att_mat = aug_att_mat / aug_att_mat.sum(axis=-1)[...,None]\n",
        "    else:\n",
        "       aug_att_mat =  att_mat\n",
        "    \n",
        "    joint_attentions = np.zeros(aug_att_mat.shape)\n",
        "\n",
        "    layers = joint_attentions.shape[0]\n",
        "    joint_attentions[0] = aug_att_mat[0].numpy()\n",
        "    for i in np.arange(1,layers):\n",
        "        joint_attentions[i] = aug_att_mat[i].numpy().dot(joint_attentions[i-1])\n",
        "        \n",
        "    return joint_attentions\n",
        "\n",
        "def plot_attention_heatmap(att, s_position, t_positions, sentence):\n",
        "\n",
        "  cls_att = np.flip(att[:,s_position, t_positions], axis=0)\n",
        "  xticklb = input_tokens= list(itertools.compress(['<cls>']+sentence.split(), [i in t_positions for i in np.arange(len(sentence)+1)]))\n",
        "  yticklb = [str(i) if i%2 ==0 else '' for i in np.arange(att.shape[0],0, -1)]\n",
        "  ax = sns.heatmap(cls_att, xticklabels=xticklb, yticklabels=yticklb, cmap=\"YlOrRd\")\n",
        "  return ax\n",
        "\n",
        "\n",
        "def convert_adjmat_tomats(adjmat, n_layers, l):\n",
        "   mats = np.zeros((n_layers,l,l))\n",
        "   \n",
        "   for i in np.arange(n_layers):\n",
        "       mats[i] = adjmat[(i+1)*l:(i+2)*l,i*l:(i+1)*l]\n",
        "       \n",
        "   return mats\n",
        "\n",
        "def compute_raw_attention_residual_connections(attentions_mat, input_tokens):\n",
        "    print(\"Get raw attention mat + residual coonections\")\n",
        "    res_att_mat = attentions_mat.sum(axis=1)/attentions_mat.shape[1]\n",
        "    res_att_mat = res_att_mat + np.eye(res_att_mat.shape[1])[None,...]\n",
        "    res_att_mat = res_att_mat / res_att_mat.sum(axis=-1)[...,None]\n",
        "    \n",
        "    res_adj_mat, res_labels_to_index = get_adjmat(mat=res_att_mat, input_tokens=input_tokens)\n",
        "    return res_adj_mat, res_labels_to_index, res_att_mat\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nJ1dCasBBmrt"
      },
      "outputs": [],
      "source": [
        "#title Get raw attention mat + residual coonections\n",
        "def plot_raw_attention_residual_connections(attentions_mat, input_tokens):\n",
        "    print(\"\\n============ RAW ATTENTION MAP + RESIDUAL CONNECTIONS ============\")\n",
        "    res_adj_mat, res_labels_to_index, res_att_mat = compute_raw_attention_residual_connections(attentions_mat=attentions_mat, input_tokens=input_tokens)\n",
        "\n",
        "    plt.figure(figsize=(20,100))\n",
        "    res_G = draw_attention_graph(res_adj_mat,res_labels_to_index, n_layers=res_att_mat.shape[0], length=res_att_mat.shape[-1])\n",
        "    return res_G\n",
        "\n",
        "def plot_attention_rollout(attentions_mat, input_tokens):\n",
        "    print(\"\\n============ ATTENTION ROLLOUT ============\")\n",
        "    res_adj_mat, res_labels_to_index, res_att_mat = compute_raw_attention_residual_connections(attentions_mat=attentions_mat, input_tokens=input_tokens)\n",
        "    joint_attentions = compute_joint_attention(res_att_mat, add_residual=False)\n",
        "    joint_att_adjmat, joint_labels_to_index = get_adjmat(mat=joint_attentions, input_tokens=input_tokens)\n",
        "    plt.figure(figsize=(20,100))\n",
        "    G = draw_attention_graph(joint_att_adjmat,joint_labels_to_index, n_layers=joint_attentions.shape[0], length=joint_attentions.shape[-1])\n",
        "\n",
        "def plot_attention_flow(attentions_mat, input_tokens, res_G):\n",
        "    print(\"\\n============ ATTENTION FLOW ============\")\n",
        "    res_adj_mat, res_labels_to_index, res_att_mat = compute_raw_attention_residual_connections(attentions_mat=attentions_mat, input_tokens=input_tokens)\n",
        "    print(\"Compute attention flow (this will take quite some time to compute)\")\n",
        "    output_nodes = []\n",
        "    input_nodes = []\n",
        "    for key in tqdm(res_labels_to_index):\n",
        "        if 'L24' in key:\n",
        "            output_nodes.append(key)\n",
        "        if res_labels_to_index[key] < attentions_mat.shape[-1]:\n",
        "            input_nodes.append(key)\n",
        "\n",
        "    flow_values = compute_flows(res_G, res_labels_to_index, input_nodes, length=attentions_mat.shape[-1])\n",
        "\n",
        "    plt.figure(figsize=(20,100))\n",
        "    flow_G = draw_attention_graph(flow_values,res_labels_to_index, n_layers=attentions_mat.shape[0], length=attentions_mat.shape[-1])\n",
        "\n",
        "\n",
        "def attention_flow(attentions, log_fp_test, selected_classes=None, selected_layers=None, selected_heads=None):\n",
        "    # token_base_positions_axis = attentions['token_base_positions_axis']\n",
        "    # attentions_last_layer = attentions['attentions_last_layer']\n",
        "\n",
        "    for target_label in selected_classes:\n",
        "        attentions_mat = attentions['attentions_all_layers'][target_label]\n",
        "        tokens = attentions['repr_token_base_positions_axis'][target_label]\n",
        "        # domain_start_idx, domain_end_idx = convert_domain_coords_in_token_indices(\"NTD\")\n",
        "        domain_end_idx = 12\n",
        "        print(domain_end_idx)\n",
        "        attentions_mat = attentions_mat[:,:,:domain_end_idx,:domain_end_idx]\n",
        "        tokens = tokens[:domain_end_idx] \n",
        "        print(attentions_mat.shape)\n",
        "        res_G = plot_raw_attention_residual_connections(attentions_mat, tokens)\n",
        "        plot_attention_rollout(attentions_mat, tokens)\n",
        "        plot_attention_flow(attentions_mat, tokens, res_G)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKEGLHgewBFs"
      },
      "outputs": [],
      "source": [
        "#@title Analysis\n",
        "if config_dict['TASK_TYPE']=='attention_flow':\n",
        "    with open(log_file, 'a') as log_fp:\n",
        "            selected_classes = [3] #[1]  #range(config_dict['N_CLASSES'])\n",
        "            attention_flow(attentions2, log_fp, selected_classes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94FeRjDoAgxv"
      },
      "source": [
        "###Entropy of attention matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qp_5qAwCA4MB"
      },
      "outputs": [],
      "source": [
        "def entropy_attentions(type_entropy, attentions, selected_classes, selected_layers, selected_heads, file_fp):\n",
        "    attentions_all_layers = attentions['attentions_all_layers']\n",
        "    \n",
        "    for target_label in selected_classes:\n",
        "        file_fp.write(f\"{type_entropy} entropy {'of eigenvalues ' if type_entropy=='Von-Neumann' else ''}of attention matrices, class '{inv_class_labels_dict[int(target_label)]}'\\n\")            \n",
        "    \n",
        "        VN_entropy_layer_attn_sum = np.zeros(n_layers)\n",
        "        Sh_entropy_layer_attn_sum = np.zeros(n_layers)\n",
        "\n",
        "        for layer in selected_layers:\n",
        "            \n",
        "            if selected_heads == 'avg':\n",
        "                #calculate the avg of attention matrices of heads of current layer\n",
        "                attn_mat_layer = attentions_all_layers[target_label][layer].mean(dim=0).cpu().detach().numpy() \n",
        "                if type_entropy==\"von_neumann_entropy_attentions\":\n",
        "                    result = compute_Von_Neumann_entropy_eigvals(attn_mat_layer, f\"layer_{layer+1}\")\n",
        "                elif type_entropy==\"shannon_entropy_attentions\":\n",
        "                    result = compute_Shannon_entropy(attn_mat_layer, f\"layer_{layer+1}\")\n",
        "                print(f\"\\t{type_entropy}_layer_{layer+1} = {result}\")\n",
        "                file_fp.write(f\"\\t{type_entropy}_layer_{layer+1} = {result}\\n\")\n",
        "\n",
        "            else:\n",
        "                for head in selected_heads:\n",
        "                    attn_mat_head = attentions_all_layers[target_label][layer][head].cpu().detach().numpy() \n",
        "                    if type_entropy==\"von_neumann_entropy_attentions\":\n",
        "                        result = compute_Von_Neumann_entropy_eigvals(attn_mat_head, f\"head_{head+1}_layer_{layer+1}\")\n",
        "                    elif type_entropy==\"shannon_entropy_attentions\":\n",
        "                        result = compute_Shannon_entropy(attn_mat_head, f\"head_{head+1}_layer_{layer+1}\")\n",
        "                    print(f\"\\t{type_entropy}_entropy_head_{head+1}_layer_{layer+1} = {result}\")\n",
        "                    file_fp.write(f\"\\t{type_entropy}_entropy_head_{head+1}_layer_{layer+1} = {result}\\n\")\n",
        "\n",
        "def plot_entropies(attentions, selected_classes, selected_layers, selected_heads):\n",
        "    attentions_all_layers = attentions['attentions_all_layers']\n",
        "    VN_entropy_layer_attn_sum = np.zeros(n_layers)\n",
        "    Sh_entropy_layer_attn_sum = np.zeros(n_layers)\n",
        "    \n",
        "    for target_label in selected_classes:\n",
        "        for layer in selected_layers:\n",
        "            for head in selected_heads:\n",
        "\n",
        "                attn_mat_head = attentions_all_layers[target_label][layer][head].cpu().detach().numpy() \n",
        "\n",
        "                VN_entropy_attn = compute_Von_Neumann_entropy_eigvals(attn_mat_head, f\"head{head+1}_layer_{layer+1}\")\n",
        "                Sh_entropy_attn = compute_Shannon_entropy(attn_mat_head, f\"head{head+1}_layer_{layer+1}\")\n",
        "\n",
        "                VN_entropy_layer_attn_sum[layer] += VN_entropy_attn\n",
        "                Sh_entropy_layer_attn_sum[layer] += Sh_entropy_attn\n",
        "            \n",
        "        VN_entropy_layer_attn_mean = VN_entropy_layer_attn_sum / len(selected_heads)\n",
        "        Sh_entropy_layer_attn_mean = Sh_entropy_layer_attn_sum / len(selected_heads)\n",
        "\n",
        "\n",
        "        # x = [i+1 for i in range(n_layers)]\n",
        "        fig, ax = plt.subplots(figsize=(6,6))\n",
        "        ax.plot(Sh_entropy_layer_attn_mean, 'b', label='Shannon entropy')\n",
        "        # ax.axis('equal')\n",
        "        leg = ax.legend()\n",
        "        plt.title(f\"Average Shannon entropy of attention matrices of each layer\")\n",
        "        plt.grid(linestyle = '--')\n",
        "        ax.set_xticks(range(n_layers))\n",
        "        ax.set_xticklabels(np.asarray(ax.get_xticks())+1)\n",
        "        #fig.yticks(list(plt.yticks()[0]) + [1])\n",
        "        ax.set_xlabel(\"Layer\")\n",
        "        ax.set_ylabel(\"Shannon entropy\")\n",
        "        plt.show()\n",
        "        fig_path = Path(math_interpret_dir) / f'Shannon_entropy_plot.jpg'\n",
        "        fig.savefig(fig_path, bbox_inches='tight')\n",
        "        plt.close()\n",
        "\n",
        "\n",
        "        # x = [i+1 for i in range(n_layers)]\n",
        "        fig, ax = plt.subplots(figsize=(6,6))\n",
        "        ax.plot(VN_entropy_layer_attn_mean, 'b', label='VN entropy')\n",
        "        # ax.axis('equal')\n",
        "        leg = ax.legend()\n",
        "        plt.title(f\"Average Von Neumann entropy of attention matrices of each layer\")\n",
        "        plt.grid(linestyle = '--')\n",
        "        ax.set_xticks(range(n_layers))\n",
        "        ax.set_xticklabels(np.asarray(ax.get_xticks())+1)\n",
        "        #fig.yticks(list(plt.yticks()[0]) + [1])\n",
        "        ax.set_xlabel(\"Layer\")\n",
        "        ax.set_ylabel(\"VN entropy\")\n",
        "        plt.show()\n",
        "        fig_path = Path(math_interpret_dir) / f'VN_entropy_plot.jpg'\n",
        "        fig.savefig(fig_path, bbox_inches='tight')\n",
        "        plt.close()\n",
        "                        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znhpo1cL_dxG"
      },
      "outputs": [],
      "source": [
        "if config_dict['TASK_TYPE']=='von_neumann_entropy_attentions' or config_dict['TASK_TYPE']=='shannon_entropy_attentions':\n",
        "    attn_eigvals_file = Path(math_interpret_dir) / f\"{config_dict['TASK_TYPE']}.txt\"\n",
        "    with open(attn_eigvals_file, 'w') as attn_eigvals_fp:\n",
        "\n",
        "        selected_classes = [7]  #attentions_all_layers.keys()\n",
        "        selected_layers = range(n_layers)\n",
        "        # selected_heads = 'avg'\n",
        "        # entropy_attentions(config_dict['TASK_TYPE'], attentions2, selected_classes, selected_layers, selected_heads, attn_eigvals_fp)\n",
        "        selected_heads = range(n_heads)\n",
        "        # entropy_attentions(config_dict['TASK_TYPE'], attentions2, selected_classes, selected_layers, selected_heads, attn_eigvals_fp)\n",
        "\n",
        "    plot_entropies(attentions2, selected_classes, selected_layers, selected_heads)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqZaYmmRrymg"
      },
      "source": [
        "### Analysis of eigenvalues of weights of Qi and Ki"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UZhG42H6UMD"
      },
      "outputs": [],
      "source": [
        "# model.parameters\n",
        "print(f'{\"parameter\": <55}: {\"mean\": <20} (std)')\n",
        "print()\n",
        "for name,param in model.named_parameters():\n",
        "    if name.endswith(\"attention.output.LayerNorm.weight\"):\n",
        "        print(f'{name: <55}: {torch.mean(param): <20} ({torch.std(param)})')\n",
        "print()\n",
        "for name,param in model.named_parameters():\n",
        "    if name.endswith(\"attention.output.LayerNorm.bias\"):\n",
        "        print(f'{name: <55}: {torch.mean(param): <20} ({torch.std(param)})')\n",
        "print()\n",
        "for name,param in model.named_parameters():\n",
        "    if name.endswith(\"output.LayerNorm.weight\") and not name.endswith(\"attention.output.LayerNorm.weight\"):\n",
        "        print(f'{name: <55}: {torch.mean(param): <20} ({torch.std(param)})')\n",
        "print()\n",
        "for name,param in model.named_parameters():\n",
        "    if name.endswith(\"output.LayerNorm.bias\") and not name.endswith(\"attention.output.LayerNorm.bias\"):\n",
        "        print(f'{name: <55}: {torch.mean(param): <20} ({torch.std(param)})')\n",
        "# print(model.parameters)\n",
        "\n",
        "# model_params = dict(model.named_parameters())\n",
        "# model_params[\"encoder.layer.0.attention.output.LayerNorm.bias\"].data.cpu().detach().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3qGrSgNb6_n"
      },
      "outputs": [],
      "source": [
        "def compute_head_weights_eigenvalues(model, dir_path):\n",
        "    layer_query_weight_names = [f'bert.encoder.layer.{l}.attention.self.query.weight' for l in range(n_layers)]\n",
        "    layer_key_weight_names = [f'bert.encoder.layer.{l}.attention.self.key.weight' for l in range(n_layers)]\n",
        "    model_params = dict(model.named_parameters())\n",
        "    for layer in np.flip(range(n_layers)):\n",
        "        w_q = model_params[layer_query_weight_names[layer]].data\n",
        "        w_k = model_params[layer_key_weight_names[layer]].data\n",
        "        emb_dim = w_q.shape[0]\n",
        "        d_k = int(emb_dim / n_heads)\n",
        "                \n",
        "        weights_prod = np.matmul(w_q, w_k.T)\n",
        "\n",
        "        eigenvals = np.linalg.eigvals(weights_prod)\n",
        "        print(eigenvals)\n",
        "        return\n",
        "        eigenvals_count = {}\n",
        "        eigenvals_count['positive'] = sum([1 for x in eigenvals if x>0])\n",
        "        eigenvals_count['negative'] = sum([1 for x in eigenvals if x<0])\n",
        "        eigenvals_count['zero'] = sum([1 for x in eigenvals if x==0])\n",
        "        \n",
        "        #eigenvals_count = collections.Counter(eigenvals)\n",
        "        print(f\"n. unique eigenvalues = {len(np.unique(eigenvals))}\")\n",
        "        fig=plt.figure(figsize=(8,8))\n",
        "        # print(np.sort_complex(eigenvals)[:10])\n",
        "        plt.bar(range(len(eigenvals_count.keys())), eigenvals_count.values(), align='center', width=0.8)\n",
        "        plt.xticks(range(len(eigenvals_count.keys())), eigenvals_count.keys(), rotation=45, fontsize=12)\n",
        "        plt.title(f\"Eigenvalues for layer {layer+1}\")\n",
        "        plt.show()\n",
        "        fig_path = Path(dir_path) / f'{layer+1}.jpg'\n",
        "        fig.savefig(fig_path, bbox_inches='tight', pad_inches=0)\n",
        "        plt.close()\n",
        "\n",
        "        # for i in range(n_heads):\n",
        "        #     w_q_i = w_q[:, i*d_k : i*d_k + d_k]\n",
        "        #     w_k_i = w_k[:, i*d_k : i*d_k + d_k]\n",
        "        #     weights_prod = np.matmul(w_q_i, w_k_i.T)\n",
        "        #     eigenvals = np.linalg.eigvals(weights_prod)\n",
        "        #     eigenvals_count = {}\n",
        "        #     eigenvals_count['positive'] = sum([1 for x in eigenvals if x>0])\n",
        "        #     eigenvals_count['negative'] = sum([1 for x in eigenvals if x<0])\n",
        "        #     eigenvals_count['zero'] = sum([1 for x in eigenvals if x==0])\n",
        "            \n",
        "        #     #eigenvals_count = collections.Counter(eigenvals)\n",
        "        #     print(f\"n. unique eigenvalues = {len(np.unique(eigenvals))}\")\n",
        "        #     plt.figure(figsize=(8,8))\n",
        "        #     # print(np.sort_complex(eigenvals)[:10])\n",
        "        #     plt.bar(range(len(eigenvals_count.keys())), eigenvals_count.values(), align='center', width=0.8)\n",
        "        #     plt.xticks(range(len(eigenvals_count.keys())), eigenvals_count.keys(), rotation=45, fontsize=12)\n",
        "        #     plt.title(f\"Eigenvalues for head {i+1} layer {layer+1}\")\n",
        "        #     plt.show()\n",
        "        #     fig_path = Path(dir_path) / f'{layer+1}_{i+1}.jpg'\n",
        "        #     fig.savefig(fig_path, bbox_inches='tight', pad_inches=0)\n",
        "        #     plt.close()\n",
        "\n",
        "def compute_max_bias(model):\n",
        "    layer_query_weight_names = [f'bert.encoder.layer.{l}.attention.self.query.bias' for l in range(n_layers)]\n",
        "    layer_key_weight_names = [f'bert.encoder.layer.{l}.attention.self.key.bias' for l in range(n_layers)]\n",
        "    model_params = dict(model.named_parameters())\n",
        "    for layer in np.flip(range(n_layers)):\n",
        "            bias_q = model_params[layer_query_weight_names[layer]].data\n",
        "            bias_k = model_params[layer_key_weight_names[layer]].data\n",
        "            print(f\"layer {layer}\")\n",
        "            print(f\"\\tbias_q={len(bias_q)}\")\n",
        "            print(f\"\\tbias_k={len(bias_k)}\")\n",
        "\n",
        "def hist_Wq_WkT(model):\n",
        "    layer_query_weight_names = [f'bert.encoder.layer.{l}.attention.self.query.weight' for l in range(n_layers)]\n",
        "    layer_key_weight_names = [f'bert.encoder.layer.{l}.attention.self.key.weight' for l in range(n_layers)]\n",
        "    model_params = dict(model.named_parameters())\n",
        "    \n",
        "    for layer in np.flip(range(n_layers)):\n",
        "        W_q = model_params[layer_query_weight_names[layer]].data.cpu().detach().numpy()\n",
        "        W_k = model_params[layer_key_weight_names[layer]].data.cpu().detach().numpy()\n",
        "        emb_dim = W_q.shape[0]\n",
        "        d_k = int(emb_dim / n_heads)\n",
        "        head = 0\n",
        "        W_q_i = W_q[:, head*d_k : head*d_k + d_k]\n",
        "        W_k_i = W_k[:, head*d_k : head*d_k + d_k]        \n",
        "        weights_prod = np.matmul(W_q_i, W_k_i.T)\n",
        "        fig, ax = plt.subplots(figsize=(15,10))\n",
        "        ax.set_aspect('equal')\n",
        "        sns.heatmap(weights_prod)\n",
        "        plt.show()\n",
        "        \n",
        "        heat_dir = Path(math_interpret_dir) / \"heatmaps_Wq_WkT\"\n",
        "        if not os.path.exists(heat_dir):\n",
        "            os.makedirs(heat_dir)\n",
        "            print(f\"Directory '{heat_dir}' created\")\n",
        "        fig_path = Path(heat_dir) / f'heatmap_Wq_WkT_L{layer+1}_H1.jpg'\n",
        "        fig.savefig(fig_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2W9-tEuKrw1E"
      },
      "outputs": [],
      "source": [
        "if config_dict['TASK_TYPE'] == 'eigenvalues_analysis':\n",
        "    head_weights_eigenvalues = compute_head_weights_eigenvalues(model, math_interpret_dir)\n",
        "    compute_max_bias(model)\n",
        "    hist_Wq_WkT(model)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}